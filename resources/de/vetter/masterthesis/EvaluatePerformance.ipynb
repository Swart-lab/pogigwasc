{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating predictive performance\n",
    "\n",
    "Compare a prediction in the form of a gff-file to curated 'true' annotation (also a gff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_filename = \"september-final-benchmarks/testing_my_ghmm_september16-day2020-09-16_101157.predicted.gff\"\n",
    "truth_filename = \"september-final-benchmarks/testing.gff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranges_overlap(a, A, b, B):\n",
    "    return a <= B and b <= A\n",
    "\n",
    "def contains(a, A, b):\n",
    "    return a <= b and b <= A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature2index = {\"NCS\": 0, \"CDS\": 1, \"intron\": 2, \"stop_codon\": 3}\n",
    "feature_names = [\"NCS\", \"CDS\", \"intron\", \"stop\"]\n",
    "\n",
    "# This code is redundant with the code used in some other notebooks, but duplicated to be able to use them on their own\n",
    "complement = {\"A\": \"T\", \"T\": \"A\", \"G\": \"C\", \"C\": \"G\", \"N\": \"N\"}\n",
    "base_order = \"TCAG\"\n",
    "codon_list = [a + b + c for a in base_order for b in base_order for c in base_order]\n",
    "\n",
    "rna_codon_list = [c.replace(\"T\", \"U\") for c in codon_list]\n",
    "\n",
    "def codon2index(codon):\n",
    "    result = base_order.index(codon[0]) * 16\n",
    "    result += base_order.index(codon[1]) * 4\n",
    "    result += base_order.index(codon[2])\n",
    "    return result\n",
    "\n",
    "\n",
    "def utr2stop_codon(feature):\n",
    "    \"\"\"\n",
    "    Convert a three_prime_utr-feature into a corresponding stop codon\n",
    "    \"\"\"\n",
    "    feature.feature = \"stop_codon\"\n",
    "    if feature.strand:\n",
    "        feature.end = feature.start + 2\n",
    "    else:\n",
    "        feature.start = feature.end - 2\n",
    "    \n",
    "\n",
    "def rev_comp(sequence: str):\n",
    "    result = \"\"\n",
    "    for i in range(len(sequence)-1, -1, -1):\n",
    "        result += complement[sequence[i]]\n",
    "    return result\n",
    "\n",
    "class Feature:\n",
    "    def __init__(self, feature: str, start: int, end: int, strand: bool):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.strand = strand\n",
    "        self.feature = feature\n",
    "        \n",
    "class Gene:\n",
    "    def __init__(self, strand: bool):\n",
    "        self.strand = strand\n",
    "        self.features = [] # a sorted (!) list of CDS, introns and one UTR; sorted from 5' to 3', \n",
    "        # Sorting is trusted to the outside world; maybe check in isValid!\n",
    "        \n",
    "    def append(self, feature: Feature):\n",
    "        self.features.append(feature)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \" \".join([\"%s%s %s %s%s\" % (\"[\" if f.strand else \"<\", \n",
    "                                           f.start, f.feature, f.end,\n",
    "                                           \">\" if f.strand else \"]\") \n",
    "                         for f in self.features])\n",
    "    def get_range(self):\n",
    "        return self.features[0].start, self.features[-1].end\n",
    "\n",
    "    def is_valid(self):\n",
    "        if len(self.features) == 0:\n",
    "            print(\"! The gene is empty\")\n",
    "            return False\n",
    "        \n",
    "        utr_index = -1 if self.strand else 0\n",
    "        first_cds_index = 0 if self.strand else -1\n",
    "        \n",
    "        # a Gene must end in an Intron\n",
    "        if self.features[utr_index].feature not in [\"three_prime_UTR\", \"stop_codon\"]:\n",
    "            print(\"! 3' Terminal feature is not a UTR, but a %s\" % self.features[utr_index].feature)\n",
    "            return False\n",
    "        # a Gene must start with a CDS\n",
    "        if self.features[first_cds_index].feature != \"CDS\":\n",
    "            print(\"! 5' terminal feature is not a CDS, but a %s\" % self.features[first_cds_index].feature)\n",
    "            return False\n",
    "        \n",
    "        # Gene must start with CDS, end with UTR (len >= 2 so far), and can have [intron, CDS]-pairs in between \n",
    "        # (no two cds adjacent, nor two introns)\n",
    "        if len(self.features) % 2 != 0:\n",
    "            print(\"! uneven number of features\")\n",
    "            return False\n",
    "        \n",
    "        num_utrs = 0\n",
    "        index = 0\n",
    "        while index < len(self.features):\n",
    "            if self.features[index].feature in [\"three_prime_UTR\", \"stop_codon\"]:\n",
    "                num_utrs += 1\n",
    "            if self.features[index+1].feature in [\"three_prime_UTR\", \"stop_codon\"]:\n",
    "                num_utrs += 1\n",
    "                \n",
    "            if self.features[index].strand != self.strand or self.features[index+1].strand != self.strand:\n",
    "                print(\"! Strand disagreement within the gene\")\n",
    "                return False\n",
    "            \n",
    "            if self.strand:\n",
    "                if not (self.features[index].feature == \"CDS\" \\\n",
    "                        and self.features[index+1].feature in [\"intron\", \"three_prime_UTR\", \"stop_codon\"]):\n",
    "                    print(\"! CDS-intron-CDS-UTR-pattern violated\")\n",
    "                    return False\n",
    "            else:\n",
    "                if not (self.features[index+1].feature == \"CDS\" \\\n",
    "                        and self.features[index].feature in [\"intron\", \"three_prime_UTR\", \"stop_codon\"]):\n",
    "                    print(\"! CDS-intron-CDS-UTR-pattern violated\")\n",
    "                    return False\n",
    "            \n",
    "            index +=2\n",
    "            \n",
    "        if num_utrs != 1:\n",
    "            print(\"! Too many utrs: %s\" % num_utrs)\n",
    "            return False   \n",
    "        \n",
    "        return True\n",
    "    \n",
    "class Annotation:\n",
    "    def __init__(self, name: str, start: int, end: int):\n",
    "        self.name = name\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.features = [] # The sorted list of features; could also separate this by strand\n",
    "        self.genes = []\n",
    "    \n",
    "    def add(self, feature: Feature):\n",
    "        index = 0\n",
    "        while index < len(self.features):\n",
    "            if self.features[index].start > feature.end:\n",
    "                self.features.insert(index, feature)\n",
    "                return\n",
    "            index += 1\n",
    "        self.features.append(feature)\n",
    "        \n",
    "    def overlaps(self, start: int, end: int, tolerance=300) -> bool:\n",
    "        \"\"\"\n",
    "        Checks whether the given range [start, end] overlaps with any of the genes held by self, extended by\n",
    "        tolerance nucleotides to both sides\n",
    "        \"\"\"\n",
    "        for g in self.genes:\n",
    "            g_start, g_end = g.get_range()\n",
    "            g_start -= tolerance\n",
    "            g_end += tolerance\n",
    "            if g_start <= end and start <= g_end:\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    def compile_genes(self) -> bool:\n",
    "        all_valid = True\n",
    "        self.genes = []\n",
    "        last_end = self.features[0].start - 1\n",
    "        current_gene = Gene(self.features[0].strand)\n",
    "        for f in self.features:\n",
    "            if f.start != last_end + 1: # there is a break\n",
    "                self.genes.append(current_gene)\n",
    "                all_valid = all_valid and current_gene.is_valid()\n",
    "                current_gene = Gene(f.strand)\n",
    "                \n",
    "            current_gene.append(f)\n",
    "            last_end = f.end\n",
    "        \n",
    "        if len(current_gene) > 0:\n",
    "            self.genes.append(current_gene)\n",
    "            all_valid = all_valid and current_gene.is_valid()\n",
    "        \n",
    "        return all_valid\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name + (\"[%s,%s]:\\n\\t\" % (self.start, self.end)) + (\"\\n\\t\".join([\"[%s, %s]%s%s\" % (f.start, f.end,\n",
    "                                                                                                       f.feature, \n",
    "                                                                                                       \"+\" if f.strand else \"-\") \n",
    "                                                                                     for f in self.features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect 'truth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curated_annotation = {}\n",
    "with open(truth_filename) as annotation_file:\n",
    "    c = 0\n",
    "    number_of_stops = 0\n",
    "    faulty = 0\n",
    "    line = annotation_file.readline()\n",
    "    current = None\n",
    "    while line:\n",
    "        line = annotation_file.readline()[:-1]\n",
    "        content = line.split(\"\\t\")\n",
    "        if line.startswith(\"##sequence-region\"):\n",
    "            print(current)\n",
    "            if current is not None:\n",
    "                correct = current.compile_genes()\n",
    "                if not correct:\n",
    "                    faulty += 1\n",
    "                print(correct)\n",
    "                print(\"Genes:\\n\\t\" + \"\\n\\t\".join([str(g) for g in current.genes]))\n",
    "                curated_annotation[current.name] = current\n",
    "            print(\"-  \" * 36)\n",
    "            \n",
    "            current = Annotation(content[1], int(content[2]), int(content[3]))\n",
    "            c += 1\n",
    "        elif len(line) > 0 and not line.startswith(\"#\"):\n",
    "            f = Feature(content[2], int(content[3]), int(content[4]), content[6] == \"+\")\n",
    "            if f.feature == \"three_prime_UTR\":\n",
    "                utr2stop_codon(f)\n",
    "            \n",
    "            if f.feature == \"stop_codon\":\n",
    "                number_of_stops += 1\n",
    "            current.add(f)\n",
    "\n",
    "print(current.compile_genes())\n",
    "print(\"Genes:\\n\\t\" + \"\\n\\t\".join([str(g) for g in current.genes]))\n",
    "curated_annotation[current.name] = current\n",
    "print(c, \"=\", len(curated_annotation), \"of which\", faulty, \"were faulty\")\n",
    "print(\"\\nThere are %s stop-codons (and thus genes) annotated\" % number_of_stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The replacement matrix\n",
    "To quantify the quality of the prediction, collect a replacement matrix: its rows correspond to what ought to be (what is found in the 'truth'), while its columns capture what is (found in the prediction-file). \n",
    "\n",
    "The row-labels are:\n",
    " - NCS (can be computed from the others + knowledge of length)\n",
    " - CDS (frame information? -> could split this into: CDS in correct frame and CDS in wrong frame)\n",
    " - intron\n",
    " - stop_codon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_annotation = {}\n",
    "report = \"\"\n",
    "report += prediction_filename + \"\\n\\n\"\n",
    "\n",
    "with open(prediction_filename) as prediction:\n",
    "    current_head = None\n",
    "    current = None\n",
    "    for r, line in enumerate(prediction):\n",
    "        if line.startswith(\"NODE\"):\n",
    "            contents = line.split(\"\\t\")\n",
    "            start = int(contents[3])\n",
    "            end = int(contents[4])\n",
    "            #if True or contents[0] in curated_annotation and curated_annotation[contents[0]].overlaps(start,end):\n",
    "            if contents[0] != current_head:\n",
    "                if current_head is not None:\n",
    "                    correct = current.compile_genes()\n",
    "                    print(current_head, \"is\", \"valid\" if correct else \"invalid\")\n",
    "                    print(current)\n",
    "                    predicted_annotation[current_head] = current\n",
    "                current_head = contents[0]\n",
    "                current = Annotation(current_head, 0, int(current_head.split(\"_\")[3]))\n",
    "            \n",
    "            if contents[2] in [\"gene\", \"transcript\", \"start_codon\"]:\n",
    "                continue\n",
    "            current.add(Feature(contents[2], start, end, contents[6] == \"+\"))\n",
    "\n",
    "    predicted_annotation[current_head] = current # the last one\n",
    "    print(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_can_be_compared = set(curated_annotation.keys()).intersection(set(predicted_annotation.keys()))\n",
    "# print(\"\\n\".join(what_can_be_compared)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the byte-arrays, and fill in annotation ([0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = {}\n",
    "flanking = 300\n",
    "for node in curated_annotation:\n",
    "    encoded[node] = np.zeros((2, int(node.split(\"_\")[3])))\n",
    "    encoded[node][0,:] = -0.5\n",
    "    length = curated_annotation[node].end\n",
    "    # first run: mark the NCS-areas around the features\n",
    "    for feature in curated_annotation[node].features:\n",
    "        encoded[node][0, feature.start-1-flanking:feature.end+flanking] = feature2index[\"NCS\"]  \n",
    "    \n",
    "    for feature in curated_annotation[node].features:\n",
    "        encoded[node][0, feature.start-1:feature.end] = feature2index[feature.feature]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for node in predicted_annotation:\n",
    "    if node in encoded:\n",
    "        length = predicted_annotation[node].end\n",
    "        for feature in predicted_annotation[node].features:\n",
    "            encoded[node][1, feature.start-1:feature.end] = feature2index[feature.feature]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Sensitivity and specificity (and stanke) from bytes\n",
    "(this one is just much slower than the other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_matrix = np.zeros((4,4))\n",
    "confusion_matrix = np.zeros((2,2)) # [Y-N, p-n]\n",
    "FP = 0\n",
    "TP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "\"\"\"\n",
    "matrix format: row=prediction, col=truth\n",
    "   p  n\n",
    "Y |TP|FP|\n",
    "N |FN|TN\n",
    "\"\"\"\n",
    "total_cds = 0\n",
    "for node in what_can_be_compared:\n",
    "    for i in range(predicted_annotation[node].end):\n",
    "        # the prediction\n",
    "        p = int(encoded[node][1,i])\n",
    "        if p == 1:\n",
    "            total_cds += 1\n",
    "\n",
    "        # the truth\n",
    "        t = encoded[node][0,i]\n",
    "\n",
    "        # no truth known here\n",
    "        if t < 0:\n",
    "            continue\n",
    "\n",
    "        t = int(t)\n",
    "        replacement_matrix[t,p] += 1\n",
    "        if p == 1:\n",
    "            if t == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1 \n",
    "        else:\n",
    "            if t==1:\n",
    "                FN += 1 \n",
    "            else:\n",
    "                TN += 1 \n",
    "        \n",
    "confusion_matrix[0,0] = TP\n",
    "confusion_matrix[0,1] = FP\n",
    "confusion_matrix[1,0] = FN\n",
    "confusion_matrix[1,1] = TN\n",
    "print(replacement_matrix) # this should be the same across both\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report += \"sensitivity = %s\\nspecificity = %s\\nstanke/precision = %s\\n\" % (TP / (TP + FN), TN / (TN + FP), TP / (TP + FP))\n",
    "print(\"sensitivity:\", TP / (TP + FN))\n",
    "print(\"specificity:\", TN / (TN + FP)) \n",
    "print(\"stanke:     \", TP / (TP + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant 2: Compute replacement matrix from annotations\n",
    "\n",
    "This requires that both the annotation and the prediction are sorted: Reads through both only once from left to right. This assumption is true for Augustus-predictions, my predictions, and my annotation\n",
    "\n",
    "Then, for every node and every gene annotated on that node, the prediction is filtered to the range of 300nt around the annotation's edges (then put into `relevant_prediction`)\n",
    "\n",
    "For every gene in the annotation, two indices are held:\n",
    " - `pred_index`: against which predicted feature is the current feature being compared?\n",
    " - `g_index`: which of the gene's features is currently being compared?\n",
    " \n",
    "Both start with the first feature (index 0). Then, all nucleotide-positions `i` are considered, and as soon as `i` reaches the end of the current predicted feature, `pred_index` is increased (if possible). **Note** that since GFF-indices are shifted by 1 and end-inclusive, this is done at the end of the loop, not the start (draw it for yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "replacement_matrix = np.zeros((4,4))\n",
    "total_cds = 0\n",
    "\n",
    "for node in what_can_be_compared: \n",
    "    truth = curated_annotation[node]\n",
    "    prediction = predicted_annotation[node]\n",
    "    relevant_prediction = [f for f in prediction.features if truth.overlaps(f.start, f.end)]\n",
    "    # print(node, [g.get_range() for g in truth.genes])\n",
    "    # print([\"%s%s %s %s%s\" % (\"[\" if f.strand else \"<\", \n",
    "    #                          f.start, f.feature, f.end,\n",
    "    #                          \">\" if f.strand else \"]\") for f in relevant_prediction])\n",
    "    for gene in truth.genes:\n",
    "        g_start, g_end = gene.get_range()\n",
    "        pred_index = 0\n",
    "        g_index = 0\n",
    "        predicted_feature = None\n",
    "        annotated_feature = feature2index[\"NCS\"]\n",
    "        for i in range(g_start - 300, g_end + 301):\n",
    "            # if i is inside current predicted feature\n",
    "            # print(node, pred_index, \"/\", len(relevant_prediction))\n",
    "            if pred_index < len(relevant_prediction) and contains(relevant_prediction[pred_index].start, \n",
    "                                                                  relevant_prediction[pred_index].end, \n",
    "                                                                  i):\n",
    "                predicted_feature = feature2index[relevant_prediction[pred_index].feature]\n",
    "            else:\n",
    "                predicted_feature = feature2index[\"NCS\"]\n",
    "\n",
    "            if contains(gene.features[g_index].start, gene.features[g_index].end, i):\n",
    "                annotated_feature = feature2index[gene.features[g_index].feature]\n",
    "            else:\n",
    "                annotated_feature = feature2index[\"NCS\"]\n",
    "\n",
    "            replacement_matrix[annotated_feature, predicted_feature] += 1\n",
    "\n",
    "            # Keep g_index and pred_index up to date: if have reached end of feature, move to next\n",
    "            if pred_index + 1 < len(relevant_prediction) and relevant_prediction[pred_index].end <= i:\n",
    "                pred_index += 1\n",
    "            if gene.features[g_index].end <= i and g_index + 1 < len(gene.features):\n",
    "                g_index += 1            \n",
    "\n",
    "    \n",
    "print(replacement_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacer = \" & \"\n",
    "print(prediction_filename)\n",
    "\n",
    "whither_matrix = replacement_matrix / np.tile(np.sum(replacement_matrix, axis=1), 4).reshape(4,4).T\n",
    "report += \"\\nwhither\" + spacer + spacer.join(feature_names) + \"\\\\\\\\\\\\hline\\n\"\n",
    "for row in range(4):\n",
    "    report += feature_names[row] + spacer\n",
    "    report += spacer.join([str(np.round(e, 5)) for e in whither_matrix[row]])\n",
    "    report += \"\\\\\\\\\\n\"\n",
    "        \n",
    "report += \"\\n\"\n",
    "whence_matrix = replacement_matrix / np.tile(np.sum(replacement_matrix, axis=0), 4).reshape(4,4)\n",
    "report += \"whence\" + spacer + spacer.join(feature_names) + \"\\\\\\\\\\\\hline\\n\"\n",
    "for row in range(4):\n",
    "    report += feature_names[row] + spacer\n",
    "    report += spacer.join([str(np.round(e, 5)) for e in whence_matrix[row]])\n",
    "    report += \"\\\\\\\\\\n\"\n",
    "    \n",
    "cds = feature2index[\"CDS\"]\n",
    "sensitivity = replacement_matrix[cds, cds] / np.sum(replacement_matrix[cds, :])\n",
    "stanke_specificity = replacement_matrix[cds, cds] / np.sum(replacement_matrix[:, cds]) # AUGUSTUS: /total_cds, requires other computation\n",
    "\n",
    "print(\"\\nsensitivity = %s\\nstanke-specificity = %s\" % (sensitivity, stanke_specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature-level sensitivity and specificity\n",
    "\n",
    "**p** is the number of *CDS* in the annotated regions\n",
    "**TP** is the number of *CDS* perfectly predicted\n",
    "\n",
    "Since **n** does not exist in a meaningful/unique way, cannot assess specificity. Then instead opt for precision:\n",
    "\n",
    "**Y** is the number of *CDS* predicted in the annotated regions (overlapping with it)\n",
    "\n",
    "Then have:\n",
    "*sensitivity* = **TP** / **p**\n",
    "*precision* = **TP** / **Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDS_TP = 0\n",
    "CDS_p = 0\n",
    "CDS_Y = 0\n",
    "\n",
    "intron_TP = 0\n",
    "intron_p = 0\n",
    "intron_Y = 0\n",
    "\n",
    "for node in what_can_be_compared:\n",
    "    truth = curated_annotation[node]\n",
    "    prediction = predicted_annotation[node]\n",
    "    relevant_prediction = [f for f in prediction.features if truth.overlaps(f.start, f.end)]\n",
    "    # print(node, [g.get_range() for g in truth.genes])\n",
    "    # print([\"%s%s %s %s%s\" % (\"[\" if f.strand else \"<\", \n",
    "    #                          f.start, f.feature, f.end,\n",
    "    #                          \">\" if f.strand else \"]\") for f in relevant_prediction])\n",
    "    for feature in truth.features:\n",
    "        if feature.feature == \"CDS\":\n",
    "            CDS_p += 1\n",
    "        elif feature.feature == \"intron\":\n",
    "            intron_p += 1\n",
    "    \n",
    "    for feature in relevant_prediction:\n",
    "        if feature.feature == \"CDS\":\n",
    "            CDS_Y += 1\n",
    "            if len([tf for tf in truth.features \n",
    "                    if tf.feature == \"CDS\" and tf.strand == feature.strand\\\n",
    "                    and tf.start == feature.start and tf.end == feature.end]) > 0:\n",
    "                print(\"Exact match on %s: %s %s%s%s\" % (node, feature.feature, feature.start, \n",
    "                                                        \"+\" if feature.strand else \"-\",\n",
    "                                                        feature.end))\n",
    "                CDS_TP += 1\n",
    "                \n",
    "        elif feature.feature == \"intron\":\n",
    "            intron_Y += 1\n",
    "            if len([tf for tf in truth.features \n",
    "                    if tf.feature == \"intron\" and tf.strand == feature.strand\\\n",
    "                    and tf.start == feature.start and tf.end == feature.end]) > 0:\n",
    "                print(\"Exact match on %s: %s %s%s%s\" % (node, feature.feature, feature.start, \n",
    "                                                        \"+\" if feature.strand else \"-\",\n",
    "                                                        feature.end))\n",
    "                intron_TP += 1\n",
    "        \n",
    "    \n",
    "print(CDS_TP, CDS_p, CDS_Y, intron_TP, intron_p, intron_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report += \"\\nExon-level:\\nsensitivity = %s\\nprecision = %s\" % (CDS_TP/CDS_p, CDS_TP/CDS_Y)\n",
    "report += \"\\nIntron-level:\\nsensitivity = %s\\nprecision = %s\" % (intron_TP/intron_p, intron_TP/intron_Y)\n",
    "\n",
    "print(report)\n",
    "with open(prediction_filename[:prediction_filename.index(\".\")] + \".report.txt\", \"w\") as outfile:\n",
    "    outfile.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
