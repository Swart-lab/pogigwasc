{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter-file generation\n",
    "### Input: raw sequences (contigs.fasta)\n",
    "### Input: annotation (annotation.gff3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_filename = \"september-final-benchmarks/training.gff\"\n",
    "sequence_filename = \"scaffolds.fasta\" # the assembly\n",
    "output_filename = \"automatic.parameters.properties\" # NOTE: previous contents of this file will be overwritten!\n",
    "\n",
    "parameters = dict()\n",
    "parameters[\"start_region_size\"] = 6\n",
    "parameters[\"stop_region_size\"] = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output: parameters.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters: To be chosen manually\n",
    " - `\"ncs_flank_size\"`: How many nt upstream of left and downstream of right end can be considered NCS?\n",
    " - `\"ncs_mean_length\"`: Manual estimate of how long an intergenic region is on average (in nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {}\n",
    "hyperparameters[\"ncs_flank_size\"] = 300\n",
    "hyperparameters[\"ncs_mean_length\"] = 1200\n",
    "hyperparameters[\"sds_size\"] = 5\n",
    "hyperparameters[\"sas_size\"] = 4\n",
    "\n",
    "# how far to extend beyond the seen range of intron lengths at the lower end\n",
    "hyperparameters[\"intron_length_tolerance_lower\"] = 3 \n",
    "# how far to extend beyond the seen range of intron lengths at the upper end\n",
    "hyperparameters[\"intron_length_tolerance_upper\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene format: CDS(begins with ATG) - intron - CDS - intron - CDS - stop_codon\n",
    "# i.e.: CDS[starts with ATG] - {intron - CDS}* - stop_codon\n",
    "# (thus, all genes have an even amount of features; start-codon is not treated separately)\n",
    "# The annotation may however also contain other features, especially (for me): three_prime_UTR \n",
    "# -> when reading the file, replace this! (might also have to ignore some features)\n",
    "\n",
    "complement = {\"A\": \"T\", \"T\": \"A\", \"G\": \"C\", \"C\": \"G\", \"N\": \"N\"}\n",
    "base_order = \"TCAG\"\n",
    "codon_list = [a + b + c for a in base_order for b in base_order for c in base_order]\n",
    "\n",
    "rna_codon_list = [c.replace(\"T\", \"U\") for c in codon_list]\n",
    "\n",
    "def codon2index(codon):\n",
    "    result = base_order.index(codon[0]) * 16\n",
    "    result += base_order.index(codon[1]) * 4\n",
    "    result += base_order.index(codon[2])\n",
    "    return result\n",
    "\n",
    "def positional_base_usage(fs):\n",
    "    positional_fs = np.zeros((3, 4))\n",
    "    for c in codon_list:\n",
    "        for i in range(3): # position in codon\n",
    "            positional_fs[i, base_order.index(c[i])] += fs[codon2index(c)]\n",
    "    return positional_fs\n",
    "\n",
    "# Simple approximation based on marginals\n",
    "def fit_codon_usage(counts):\n",
    "    positional_fs = positional_base_usage(counts)\n",
    "    independent_codon_approximation = np.zeros(64)\n",
    "    for c in codon_list:\n",
    "        independent_codon_approximation[codon2index(c)] = np.product([positional_fs[i, \n",
    "                                                                                    base_order.index(c[i])] \n",
    "                                                                      for i in range(3)])\n",
    "    \n",
    "    return independent_codon_approximation\n",
    "\n",
    "def rev_comp(sequence: str):\n",
    "    result = \"\"\n",
    "    for i in range(len(sequence)-1, -1, -1):\n",
    "        result += complement[sequence[i]]\n",
    "    return result\n",
    "\n",
    "class Feature:\n",
    "    def __init__(self, feature: str, start: int, end: int, strand: bool):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.strand = strand\n",
    "        self.feature = feature\n",
    "    \n",
    "class Gene:\n",
    "    def __init__(self, strand: bool):\n",
    "        self.strand = strand\n",
    "        self.features = [] # a sorted (!) list of CDS, introns and one UTR; sorted from 5' to 3', \n",
    "        # i.e. on reverse strand, the indices of subsequent features;\n",
    "        # Sorting is trusted to the outside world; maybe check in isValid!\n",
    "        \n",
    "    def append(self, feature: Feature):\n",
    "        self.features.append(feature)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \" \".join([\"%s%s %s %s%s\" % (\"[\" if f.strand else \"<\", \n",
    "                                           f.start, f.feature, f.end,\n",
    "                                           \">\" if f.strand else \"]\") \n",
    "                         for f in self.features])\n",
    "\n",
    "    def get_range(self):\n",
    "        return self.features[0].start, self.features[-1].end\n",
    "    \n",
    "    # sequence is nucleotide sequence from scaffolds.fasta\n",
    "    # this produces the concatenated cds -- potentially complementarily reversed (if strand is negative)\n",
    "    def get_contiguous_cds(self, sequence: str):\n",
    "        cds = \"\".join([sequence[(f.start-1):f.end] for f in self.features if f.feature == \"CDS\"])\n",
    "        if self.strand:\n",
    "            return cds\n",
    "        else:\n",
    "            return rev_comp(cds)\n",
    "        \n",
    "    def codon_usage(self, sequence: str):\n",
    "        cds = self.get_contiguous_cds(sequence)\n",
    "        general = np.zeros(64)\n",
    "        stop = np.zeros(64)\n",
    "        general_n = 0\n",
    "        for i in range(0, len(cds) - 21, 3):\n",
    "            general[codon2index(cds[i:i+3])] += 1\n",
    "            general_n += 1\n",
    "            \n",
    "        for i in range(len(cds) - 21, len(cds), 3):\n",
    "            stop[codon2index(cds[i:i+3])] += 1\n",
    "            \n",
    "        print(\"term: %s : %s*UGA\" % (cds[len(cds)-21:], stop[codon2index(\"TGA\")]))\n",
    "        return general, general_n, stop\n",
    "        \n",
    "    def count_UGA(self, sequence: str):\n",
    "        inframe = 0\n",
    "        outframe_in_cds = 0\n",
    "        cds = self.get_contiguous_cds(sequence)\n",
    "        for i in range(len(cds)-3):\n",
    "            if sequence[i:i+3] == \"TGA\":\n",
    "                if i % 3 == 0:\n",
    "                    inframe += 1\n",
    "                else:\n",
    "                    outframe_in_cds += 1\n",
    "        # REQUIRES this gene be valid\n",
    "        # Pure sanity check\n",
    "        if self.strand:\n",
    "            stop = sequence[(self.features[-1].start-1):self.features[-1].end].count(\"TGA\")\n",
    "        else:\n",
    "            stop = sequence[(self.features[0].start-1):self.features[0].end].count(\"TCA\")\n",
    "        \n",
    "        \n",
    "        return inframe, outframe_in_cds, stop\n",
    "        \n",
    "    def get_exon_intron_stats(self):\n",
    "        \"\"\"\n",
    "        returns the 'exon'-lengths and intron-lengths found in this gene. The intron-lengths are exactly that, \n",
    "        but the exon-lengths are cleaned of everything that is not modeled by the CDS-state in the GHMM: \n",
    "        start-codon, stop-region, intron-flanking interrupted codons (which makes little difference, but still)\n",
    "        \"\"\"\n",
    "        exon_lengths = []\n",
    "        intron_lengths = []\n",
    "        i = 0 # index of feature\n",
    "        after_intron = 0 # how many bases of a codon come after the last intron (codon interrupted)\n",
    "        \n",
    "        for f in self.features:\n",
    "            if f.feature == \"CDS\":\n",
    "                length = f.end - f.start + 1 - after_intron # +1 bc. gff is inclusive-end\n",
    "                if self.strand:\n",
    "                    if i==0:\n",
    "                        length -= 3 # cut off start-codon\n",
    "                    elif i==len(self.features):\n",
    "                        length -= parameters[\"stop_region_size\"] - 3 # cut off stop-region, but not stop-codon\n",
    "                else:\n",
    "                    if i==0:\n",
    "                        length -= parameters[\"stop_region_size\"] - 3\n",
    "                    elif i==len(self.features):\n",
    "                        length -= 3 # cut off start-codon\n",
    "                after_intron = (3 - (length % 3)) % 3 # from deviation from threevenness: get what needs to be cut off next\n",
    "                length -= (3-after_intron) % 3 # cut off the part before the intron of the current exon\n",
    "                exon_lengths += [length]\n",
    "            elif f.feature == \"intron\":\n",
    "                intron_lengths += [f.end - f.start + 1]\n",
    "            i += 1\n",
    "        \n",
    "        return exon_lengths, intron_lengths\n",
    "        \n",
    "    def is_valid(self):\n",
    "        if len(self.features) == 0:\n",
    "            print(\"! The gene is empty\")\n",
    "            return False\n",
    "        \n",
    "        stop_index = -1 if self.strand else 0\n",
    "        first_cds_index = 0 if self.strand else -1\n",
    "        \n",
    "        # a Gene must end in a stop_codon\n",
    "        if self.features[stop_index].feature != \"stop_codon\":\n",
    "            print(\"! 3' Terminal feature is not a stop_codon, but a %s\" % self.features[stop_index].feature)\n",
    "            return False\n",
    "        # a Gene must start with a CDS\n",
    "        if self.features[first_cds_index].feature != \"CDS\":\n",
    "            print(\"! 5' terminal feature is not a CDS, but a %s\" % self.features[first_cds_index].feature)\n",
    "            return False\n",
    "        \n",
    "        # Gene must start with CDS, end with UTR (len >= 2 so far), and can have [intron, CDS]-pairs in between \n",
    "        # (no two cds adjacent, nor two introns)\n",
    "        if len(self.features) % 2 != 0:\n",
    "            print(\"! uneven number of features\")\n",
    "            return False\n",
    "        \n",
    "        num_stops = 0\n",
    "        index = 0\n",
    "        while index < len(self.features):\n",
    "            if self.features[index].feature == \"stop_codon\":\n",
    "                num_stops += 1\n",
    "            if self.features[index+1].feature == \"stop_codon\":\n",
    "                num_stops += 1\n",
    "                \n",
    "            if self.features[index].strand != self.strand or self.features[index+1].strand != self.strand:\n",
    "                print(\"! Strand disagreement within the gene\")\n",
    "                return False\n",
    "            \n",
    "            if self.strand:\n",
    "                if not (self.features[index].feature == \"CDS\" \\\n",
    "                        and self.features[index+1].feature in [\"intron\", \"stop_codon\"]):\n",
    "                    print(\"! CDS-intron-CDS-stop_codon-pattern violated\")\n",
    "                    return False\n",
    "            else:\n",
    "                if not (self.features[index+1].feature == \"CDS\" \\\n",
    "                        and self.features[index].feature in [\"intron\", \"stop_codon\"]):\n",
    "                    print(\"! CDS-intron-CDS-stop_codon-pattern violated\")\n",
    "                    return False\n",
    "            \n",
    "            index +=2\n",
    "            \n",
    "        if num_stops != 1:\n",
    "            print(\"! Too many stops: %s\" % num_stops)\n",
    "            return False   \n",
    "        \n",
    "        return True\n",
    "\n",
    "class Annotation:\n",
    "    def __init__(self, name: str, start: int, end: int):\n",
    "        self.name = name\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.features = [] # The list of features; could also separate this by strand\n",
    "        self.genes = []\n",
    "    \n",
    "    def add(self, feature: Feature):\n",
    "        index = 0\n",
    "        while index < len(self.features):\n",
    "            if self.features[index].start > feature.end:\n",
    "                self.features.insert(index, feature)\n",
    "                return\n",
    "            index += 1\n",
    "        self.features.append(feature)\n",
    "        \n",
    "    def compile_genes(self) -> bool:\n",
    "        all_valid = True\n",
    "        self.genes = []\n",
    "        last_end = self.features[0].start - 1\n",
    "        current_gene = Gene(self.features[0].strand)\n",
    "        for f in self.features:\n",
    "            if f.start != last_end + 1: # there is a break\n",
    "                self.genes.append(current_gene)\n",
    "                all_valid = all_valid and current_gene.is_valid()\n",
    "                current_gene = Gene(f.strand)\n",
    "                \n",
    "            current_gene.append(f)\n",
    "            last_end = f.end\n",
    "        \n",
    "        if len(current_gene) > 0:\n",
    "            self.genes.append(current_gene)\n",
    "            all_valid = all_valid and current_gene.is_valid()\n",
    "        \n",
    "        return all_valid\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name + \":\\n\\t\" + (\"\\n\\t\".join([\"[%s, %s]%s%s\" % (f.start, f.end,\n",
    "                                                                     f.feature, \n",
    "                                                                     \"+\" if f.strand else \"-\") \n",
    "                                               for f in self.features]))\n",
    "    \n",
    "def format_matrix(matrix):\n",
    "    return \"{{%s}}\" % \"}\\\\\\n  {\".join([\", \".join([str(e) for e in row]) for row in matrix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input: Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotations = []\n",
    "with open(annotation_filename) as annotation_file:\n",
    "    c = 0\n",
    "    f = 0\n",
    "    line = annotation_file.readline()\n",
    "    current = None\n",
    "    while line:\n",
    "        line = annotation_file.readline()[:-1]\n",
    "        content = line.split(\"\\t\")\n",
    "        if line.startswith(\"##sequence-region\"):\n",
    "            print(current)\n",
    "            if current is not None:\n",
    "                correct = current.compile_genes()\n",
    "                if not correct:\n",
    "                    f += 1\n",
    "                print(\"+ valid gene structure\" if correct else \"/!\\\\ invalid gene structure\")\n",
    "                print(\"Genes:\\n\\t\" + \"\\n\\t\".join([str(g) for g in current.genes]))\n",
    "                annotations.append(current)\n",
    "            print(\"-  \" * 36)\n",
    "            \n",
    "            current = Annotation(content[1], int(content[2]), int(content[3]))\n",
    "            c += 1\n",
    "        elif len(line) > 0 and not line.startswith(\"#\"):\n",
    "            # Transform 3'UTR-annotation into stop-codons!\n",
    "            feature = content[2]\n",
    "            forward = content[6] == \"+\"\n",
    "            start = int(content[3])\n",
    "            end = int(content[4])\n",
    "            if feature == \"three_prime_UTR\":\n",
    "                if forward:\n",
    "                    end = start+2\n",
    "                else:\n",
    "                    start = end-2\n",
    "                feature = \"stop_codon\"\n",
    "                \n",
    "            current.add(Feature(feature, start, end, forward))\n",
    "\n",
    "print(current.compile_genes())\n",
    "print(\"Genes:\\n\\t\" + \"\\n\\t\".join([str(g) for g in current.genes]))\n",
    "annotations.append(current)\n",
    "print(c, \"=\", len(annotations), \"of which\", f, \"were faulty\")\n",
    "\n",
    "annotation_dict = {a.name:a for a in annotations}\n",
    "num_of_genes = np.sum([len(a.genes) for a in annotations])\n",
    "print(\"There are %s genes annotated\" % num_of_genes)\n",
    "\n",
    "\n",
    "# Get information that does not require sequences:\n",
    "intron_lengths = []\n",
    "exon_lengths = []\n",
    "intron_counts = []\n",
    "for ann in annotations:\n",
    "    for gene in ann.genes:\n",
    "        el, il = gene.get_exon_intron_stats()\n",
    "        exon_lengths += el\n",
    "        intron_lengths += il\n",
    "        if (len(il) > 0 and np.max(il) > 30):\n",
    "            print(ann.name, il)\n",
    "            # Can see that the two largest ones (58, 85) are from 615, \n",
    "            # and are not very trusted (coverage-signal is ambiguous)\n",
    "        intron_counts += [len(il)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input: Raw sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros((num_of_genes,3))\n",
    "codon_usage_general = np.zeros(64)\n",
    "codon_usage_stop = np.zeros(64)\n",
    "codon_number = 0\n",
    "stop_codon_number = 0\n",
    "\n",
    "start_upstream = 3\n",
    "start_regions = []\n",
    "introns_by_length = {}\n",
    "ncs_base_counts = np.zeros(4)\n",
    "\n",
    "current_header = None\n",
    "current_sequence = \"\"\n",
    "gene_index = 0\n",
    "with open(sequence_filename) as scaffolds:\n",
    "    for row, line in enumerate(scaffolds):\n",
    "        if line.startswith(\">\"):\n",
    "            # Here query the analysis\n",
    "            if current_header is not None:\n",
    "                if current_header in annotation_dict:\n",
    "                    print(current_header)\n",
    "                    ann = annotation_dict[current_header]\n",
    "                    for gene in ann.genes:\n",
    "                        # Collect base-frequencies in flanking NCS\n",
    "                        \n",
    "                        start, end = gene.get_range()\n",
    "                        ncs_left = current_sequence[max(0, start -1 -hyperparameters[\"ncs_flank_size\"]): start]\n",
    "                        ncs_right = current_sequence[end: min(end+hyperparameters[\"ncs_flank_size\"], len(current_sequence))]\n",
    "                        ncs = ncs_left + ncs_right\n",
    "                        \n",
    "                        for i in range(4):\n",
    "                            ncs_base_counts[i] += ncs.count(base_order[i])\n",
    "                        \n",
    "                        # Collect number of inframe-stops, outframe-stops, and check for presence of stop as annotated\n",
    "                        counts[gene_index, :] = np.array(gene.count_UGA(current_sequence))\n",
    "                        print(\"\\t\", counts[gene_index,:])\n",
    "                        if counts[gene_index,2] == 0:\n",
    "                            print(\"\\t\\t\\t\\t!>!>!>missing STOP\")\n",
    "                            \n",
    "                        # Collect codon usage in CDS and stop regions\n",
    "                        cds_codon_counts, cds_num_of_codons, stop_region = gene.codon_usage(current_sequence)\n",
    "                        codon_number += cds_num_of_codons\n",
    "                        stop_codon_number += 7\n",
    "                        codon_usage_general += cds_codon_counts\n",
    "                        codon_usage_stop += stop_region\n",
    "                        \n",
    "                        gene_index += 1\n",
    "                        \n",
    "                        # Collect intron sequences:\n",
    "                        for f in [f for f in gene.features if f.feature == \"intron\"]:\n",
    "                            curr_intron = current_sequence[(f.start-1):f.end]\n",
    "                            curr_intron_length = f.end - f.start + 1\n",
    "                            if not f.strand:\n",
    "                                curr_intron = rev_comp(curr_intron)\n",
    "                            if curr_intron_length not in introns_by_length:\n",
    "                                introns_by_length[curr_intron_length] = [curr_intron]\n",
    "                            else:\n",
    "                                introns_by_length[curr_intron_length] += [curr_intron]\n",
    "                            \n",
    "                            print(\"intron: \", curr_intron)\n",
    "                            \n",
    "                        # Collect start-region:\n",
    "                        g_start, g_end = gene.get_range()\n",
    "                        if gene.strand:\n",
    "                            start_regions += [current_sequence[max(0, g_start-1-start_upstream):\n",
    "                                                               min(len(current_sequence), g_start+2)]]\n",
    "                        else:\n",
    "                            start_regions += [rev_comp(current_sequence[max(0, g_end-3):\n",
    "                                                                        min(len(current_sequence), g_end+start_upstream)])]\n",
    "                        if not start_regions[-1].endswith(\"ATG\"):\n",
    "                            print(\"! weird Start-region\", start_regions[-1], \"\\n\")\n",
    "            \n",
    "            current_header = line[1:-1]\n",
    "            current_sequence = \"\"\n",
    "        else:\n",
    "            current_sequence += line[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCS-parameters\n",
    " - Estimate NCS-base-frequency from flanking NCS\n",
    " - How estimate NCS-length? Have user specify mean NCS-length estimate (allowed to be manual), thence geometric estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncs_base_frequencies = ncs_base_counts / np.sum(ncs_base_counts)\n",
    "parameters[\"base_frequencies_NCS\"] = \"{%s}\" % \", \".join([str(f) for f in ncs_base_frequencies])\n",
    "parameters[\"transition_probability_of_staying_in_NCS\"] = 1-1/hyperparameters[\"ncs_mean_length\"]\n",
    "\n",
    "print(\"%GC in NCS =\", ncs_base_frequencies[1] + ncs_base_frequencies[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDS-parameters\n",
    " - Estimate probability to stay in CDS by assuming geometric **distr. of cds/exon length** (mean)\n",
    " - Estimate probability of going to stop by assuming geometric model of **number of introns** (mean)\n",
    " - Compute empirical **positional base frequency marginals**\n",
    " - For Stop-region: compute empirical **codon usage** outside stop-regions\n",
    " \n",
    "For the probability of staying in CDS (with mean length $\\mu$ in nucleotides, thus mean length in codons $\\frac{\\mu}{3}$): $p_{leave} = \\frac{1}{\\frac{\\mu}{3}} = \\frac{3}{\\mu}$ and thus $p_{stay} = 1-\\frac{3}{\\mu}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There should not be any exon-length not divisible by three, and there are\", \n",
    "      np.sum([l % 3 for l in exon_lengths]), \"which are not divisible by 3\\n\")\n",
    "\n",
    "parameters[\"transition_probability_of_staying_in_CDS\"] = 1 - 3 / np.mean(exon_lengths)\n",
    "parameters[\"transition_probability_of_CDS_to_stop_given_that_CDS_is_being_left\"] = 1/(1+np.mean(intron_counts))\n",
    "\n",
    "cds_positional_marginals = positional_base_usage(codon_usage_general / codon_number)\n",
    "\n",
    "parameters[\"base_frequency_marginals_CDS\"] = format_matrix(cds_positional_marginals)\n",
    "\n",
    "# Compute the GC-content:\n",
    "gc = cds_positional_marginals[:,1] + cds_positional_marginals[:,3]\n",
    "\n",
    "print(\"%GC in CDS =\", np.mean(gc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_codon_frequencies_stop = codon_usage_stop / stop_codon_number\n",
    "empirical_codon_frequencies_general = codon_usage_general / codon_number\n",
    "\n",
    "# print(\"{%s}\" % \", \".join([str(i) for i in empirical_codon_frequencies_stop]))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,3)\n",
    "print(\"blue: empirical\")\n",
    "print(\"orange: base-wisee\")\n",
    "# Plot: which codons are the most informative w.r.t. stop vs general:\n",
    "w = 0.3\n",
    "plt.bar(np.arange(64)-w/2, empirical_codon_frequencies_general, width=w, label=\"empirical\")\n",
    "plt.bar(np.arange(64)+w/2, fit_codon_usage(empirical_codon_frequencies_general), width=w, label=\"base-wise\")\n",
    "plt.xticks(range(64), codon_list, rotation=90)\n",
    "plt.ylabel(\"probability of seeing the codon\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start region parameters\n",
    "These are difficult to infer automatically (especially the length of the pattern); can infer the base-probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_region_bases = np.zeros((start_upstream + 3, 4))\n",
    "# ADDING PSEUDOCOUNTS upstream of AUG:\n",
    "print(\"Adding pseudo-counts:\")\n",
    "start_region_bases[:3,:] = 1\n",
    "print(start_region_bases, \"\\n\")\n",
    "\n",
    "for r in [r for r in start_regions if len(r) == start_upstream + 3]:\n",
    "    for i in range(start_upstream + 3):\n",
    "        start_region_bases[i, base_order.index(r[i])] += 1\n",
    "        \n",
    "actual_start_region = start_region_bases / (num_of_genes + 4) # +4 pseudocounts!\n",
    "print(\"Sanity check: the last 3 rows should show deterministic ATG\")\n",
    "print(actual_start_region)\n",
    "actual_start_region = np.mean(actual_start_region[:3,:], axis=0)\n",
    "print(\"\\nThence, the average over the three nucleotides is:\")\n",
    "print(actual_start_region, \"\\tsum\", np.sum(actual_start_region))\n",
    "parameters[\"base_frequencies_start_region_upstream\"] = \"{%s}\" % \", \".join([str(p) for p in actual_start_region])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop region parameters\n",
    "Size is fixed; like for start-region, this has to be done manually (_could_ try some sort of automation, but likely not very good, and not worth the effort)\n",
    " - Compute empirical **positional base frequency marginals**\n",
    " - Compute empirical **codon usage** in and outside stop region\n",
    " - Force UGA to 0\n",
    " - Force UAA to empirical (low) frequency\n",
    " - Find the codon which maximises the difference between codon-wise $stopregion - cds$ and base-wise $stopregion - cds$ (cf `StopCodons.ipynb`) and correct its probability\n",
    " - Find a compensatory codon, and correct its probability (4 codons explicit)\n",
    " \n",
    "The latter part can be extended: Could also pick the top 3 most devious codons, and then 2 compensatory ones etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stop_positional_marginals = positional_base_usage(codon_usage_stop / stop_codon_number)\n",
    "parameters[\"base_frequency_marginals_stop_region\"] = format_matrix(stop_positional_marginals)\n",
    "\n",
    "def difference_of_approximation(empirical_close, empirical_far, approx_close, approx_far):\n",
    "    return (empirical_close - empirical_far) - (approx_close - approx_far)\n",
    "\n",
    "# Finding another two codons to be included:\n",
    "basewise_codon_frequencies_stop = fit_codon_usage(empirical_codon_frequencies_stop)\n",
    "basewise_codon_frequencies_general = fit_codon_usage(empirical_codon_frequencies_general)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,7)\n",
    "\n",
    "print(\"blue: empirical\")\n",
    "print(\"orange: base-wise/approximate\")\n",
    "# Plot: which codons are the most informative w.r.t. stop vs general:\n",
    "w = 0.3\n",
    "plt.subplot(3,1,1)\n",
    "plt.bar(np.arange(64)-w/2, empirical_codon_frequencies_stop - empirical_codon_frequencies_general, width=w)\n",
    "plt.bar(np.arange(64)+w/2, basewise_codon_frequencies_stop - basewise_codon_frequencies_general, width=w)\n",
    "plt.xticks(range(64), codon_list, rotation=90)\n",
    "plt.ylabel(\"f stop - f cds\")\n",
    "\n",
    "# Plot before:\n",
    "plt.subplot(3,1,2)\n",
    "plt.bar(np.arange(64)-w/2, empirical_codon_frequencies_stop, width=w)\n",
    "plt.bar(np.arange(64)+w/2, basewise_codon_frequencies_stop, width=w)\n",
    "plt.xticks(range(64), [\"\"] * 64)\n",
    "plt.ylabel(\"f stop\")\n",
    "\n",
    "# Corrections:\n",
    "explicit = {\"TGA\": 0, \"TAA\": empirical_codon_frequencies_stop[codon2index(\"TAA\")]}\n",
    "\n",
    "print(\"Adding TGA: 0\\tfrom prior knowledge\")\n",
    "print(\"Adding TAA: %s\\tfrom prior knowledge\" % explicit[\"TAA\"])\n",
    "\n",
    "diff = difference_of_approximation(empirical_codon_frequencies_stop, \n",
    "                                   empirical_codon_frequencies_general, \n",
    "                                   basewise_codon_frequencies_stop, \n",
    "                                   basewise_codon_frequencies_general)\n",
    "diff[codon2index(\"TGA\")] = 0\n",
    "diff[codon2index(\"TAA\")] = 0\n",
    "abs_diff = np.absolute(diff)\n",
    "\n",
    "most_prominent_deviant = codon_list[np.argmax(abs_diff)]\n",
    "explicit[most_prominent_deviant] = empirical_codon_frequencies_stop[np.argmax(abs_diff)]\n",
    "\n",
    "print(\"Adding %s: %s\" % (most_prominent_deviant, explicit[most_prominent_deviant]))\n",
    "\n",
    "diff[np.argmax(abs_diff)] = 0\n",
    "\n",
    "corrected_sum = 0\n",
    "basewise_sum = 0\n",
    "for codon in explicit:\n",
    "    corrected_sum += explicit[codon]\n",
    "    basewise_sum += basewise_codon_frequencies_stop[codon2index(codon)]\n",
    "    # print(\"+\", codon, corrected_sum, basewise_sum)\n",
    "desired_deviation = basewise_sum - corrected_sum\n",
    "# print(desired_deviation)\n",
    "\n",
    "# Find compensator:\n",
    "diff = empirical_codon_frequencies_stop - basewise_codon_frequencies_stop\n",
    "candidates = sorted([c for c in codon_list if c not in [\"TGA\", \"TAA\", most_prominent_deviant]], \n",
    "                    key=lambda codon: abs(diff[codon2index(codon)] - desired_deviation))\n",
    "\n",
    "explicit[candidates[0]] = empirical_codon_frequencies_stop[codon2index(candidates[0])]\n",
    "print(\"Adding %s: %s\\tas a compensator\" % (candidates[0], explicit[candidates[0]]))\n",
    "\n",
    "explicit[candidates[0]] = basewise_codon_frequencies_stop[codon2index(candidates[0])] + desired_deviation\n",
    "print(\"but correcting to %s\" % explicit[candidates[0]])\n",
    "\n",
    "print(\"\\nthereby, the corrections are:\")\n",
    "sums = np.zeros(2)\n",
    "for c in explicit:\n",
    "    print(\"  %s: %s\\t-> %s\" % (c, basewise_codon_frequencies_stop[codon2index(c)], explicit[c]))\n",
    "    sums += np.array([basewise_codon_frequencies_stop[codon2index(c)], explicit[c]])\n",
    "print(\"summing up to: %s -> %s\" % (sums[0], sums[1]))\n",
    "\n",
    "parameters[\"explicit_codon_probabilities_stop_region\"] = \"{%s}\" % \", \".join([\"%s: %s\" % (k, explicit[k]) \n",
    "                                                                             for k in explicit])\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.bar(np.arange(64)-w/2, empirical_codon_frequencies_stop, width=w)\n",
    "plt.bar(np.arange(64)+w/2, [explicit[codon] if codon in explicit else basewise_codon_frequencies_stop[codon2index(codon)] \n",
    "                            for codon in codon_list], width=w)\n",
    "plt.xticks(range(64), [(\"*%s\" % c) if c in explicit else c for c in codon_list], rotation=90)\n",
    "plt.ylabel(\"f stop (corrected)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical stop-region, with pseudocounts except on UGA.\n",
    "pseudocounts = np.ones(64)\n",
    "pseudocounts[codon2index(\"TGA\")] = 0\n",
    "\n",
    "print(\"{\" + \", \".join([str(f) for f in (codon_usage_stop + pseudocounts) / (stop_codon_number + 63)]) + \"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intron parameters\n",
    " - collect **intron lengths**\n",
    " - Compute intron length median/mean (for Poisson $\\lambda$)\n",
    " - find min and max intron length; find 5% and 95% quantiles; extend from quantiles (subsequent AUGUSTUS can still concern itself with long introns) -- preferably add asymmetric length-overshoot (hyperparameter)\n",
    " - manually set SDS- and SAS-size\n",
    " - collect **empirical base-frequencies at SDS, SAS, and in between**\n",
    " \n",
    " - **For Poisson** only need the mean (+ min and max for truncation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"intron lengths: min=%s  mean=%s  max=%s\" % (np.min(intron_lengths), np.mean(intron_lengths), np.max(intron_lengths)))\n",
    "print(np.mean(intron_counts))\n",
    "\n",
    "parameters[\"intron_minimum_length\"] = np.min(intron_lengths) - hyperparameters[\"intron_length_tolerance_lower\"]\n",
    "parameters[\"intron_maximum_length\"] = np.max(intron_lengths) + hyperparameters[\"intron_length_tolerance_upper\"]\n",
    "parameters[\"intron_mean_length\"] = np.mean(intron_lengths)\n",
    "\n",
    "# # v # SEQUENCE information # v # #\n",
    "\n",
    "sds_frequencies = np.zeros((hyperparameters[\"sds_size\"], 4))\n",
    "sas_frequencies = np.zeros((hyperparameters[\"sas_size\"], 4))\n",
    "intron_base_frequencies = np.zeros(4)\n",
    "\n",
    "# ADD PSEUDOCOUNTS!\n",
    "sds_frequencies[2:,:] = 1\n",
    "sas_frequencies[:-2,:] = 1\n",
    "\n",
    "for l in introns_by_length:\n",
    "    for intron in introns_by_length[l]:\n",
    "        sds = intron[:hyperparameters[\"sds_size\"]]\n",
    "        for i in range(len(sds)):\n",
    "            sds_frequencies[i, base_order.index(sds[i])] += 1\n",
    "        \n",
    "        middle = intron[hyperparameters[\"sds_size\"]:-hyperparameters[\"sas_size\"]]\n",
    "        for i in range(len(middle)):\n",
    "            intron_base_frequencies[base_order.index(middle[i])] += 1\n",
    "            \n",
    "        sas = intron[-hyperparameters[\"sas_size\"]:]\n",
    "        for i in range(len(sas)):\n",
    "            sas_frequencies[i, base_order.index(sas[i])] += 1\n",
    "        # print(\"%s %s %s\" % (sds, middle, sas))\n",
    "        \n",
    "parameters[\"intron_base_frequencies_splice_donor_site\"] = format_matrix((sds_frequencies.T / np.sum(sds_frequencies, \n",
    "                                                                                                    axis=1)).T)\n",
    "parameters[\"intron_base_frequencies_splice_acceptor_site\"] = format_matrix((sas_frequencies.T / np.sum(sas_frequencies, \n",
    "                                                                                                       axis=1)).T)\n",
    "parameters[\"intron_base_frequencies\"] = \"{%s}\" % \", \".join([str(f) \n",
    "                                                            for f \n",
    "                                                            in intron_base_frequencies / np.sum(intron_base_frequencies)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_filename, \"w\") as out:\n",
    "    result = \"# automatically generated parameter file\\n\"\n",
    "    result += \"# from annotation file: \" + annotation_filename + \"\\n\"\n",
    "    result += \"# and sequence file: \" + sequence_filename + \"\\n\"\n",
    "    result += \"### Hyperparameters: \\n\"\n",
    "    for key in hyperparameters:\n",
    "        result += \"# %s: %s\\n\" % (key, hyperparameters[key])\n",
    "    \n",
    "    for key in parameters:\n",
    "        result += \"%s: %s\" % (key, parameters[key])\n",
    "        result += \"\\n\"\n",
    "    \n",
    "    out.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
