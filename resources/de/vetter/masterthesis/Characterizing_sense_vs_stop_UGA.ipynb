{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing sense vs stop UGA\n",
    "\n",
    "This notebook contains the code to reproduce the results for _phase 1_ of the Master-thesis\n",
    "\n",
    "## 0: Implementation of (some of) the used data-structures and algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the global encoding of the bases and codons as numbers:\n",
    "base_order = \"TCAG\"\n",
    "codon_list = [a + b + c for a in base_order for b in base_order for c in base_order]\n",
    "rna_codon_list = [c.replace(\"T\", \"U\") for c in codon_list]\n",
    "\n",
    "def codon2index(codon):\n",
    "    result = base_order.index(codon[0]) * 16\n",
    "    result += base_order.index(codon[1]) * 4\n",
    "    result += base_order.index(codon[2])\n",
    "    return result\n",
    "\n",
    "\n",
    "### Simple approximation based on marginals\n",
    "def fit_codon_usage(counts):\n",
    "    \"\"\"\n",
    "    Produces an independent codon approximation based on the given counts: This means that three categoricals \n",
    "    over the nucleobases, one for each position in a codon will be inferred (as the marginals of the empirical codon usage)\n",
    "    counts: The counts of the codons (unnormalised empirical), a 64-entry array\n",
    "    \"\"\"\n",
    "    positional_fs = np.zeros((3, 4))\n",
    "    for c in codon_list:\n",
    "        for i in range(3): # position in codon\n",
    "            positional_fs[i, base_order.index(c[i])] += counts[codon2index(c)]\n",
    "\n",
    "    independent_codon_approximation = np.zeros(64)\n",
    "    for c in codon_list:\n",
    "        independent_codon_approximation[codon2index(c)] = np.product([positional_fs[i, base_order.index(c[i])] \n",
    "                                                                      for i in range(3)])\n",
    "    \n",
    "    return independent_codon_approximation\n",
    "\n",
    "### Classes and functions for handling the raw data\n",
    "class Transcript:\n",
    "    \n",
    "    def __init__(self, head, sequence=\"\"):\n",
    "        self.head = head\n",
    "        self.sequence = sequence\n",
    "        self.hits = []\n",
    "        self.stop_codon = \"TGA\"\n",
    "        \n",
    "    def has_hits(self, count_reverse_Complement=False):\n",
    "        return len([h for h in self.hits if h.frame >= 0]) > 0\n",
    "        \n",
    "    def closest_to_c_terminus(self):\n",
    "        if not self.has_hits():\n",
    "            return None, None\n",
    "        hit_index = np.argmax([h.end_index for h in self.hits if h.frame >= 0]) # exclude rev'comp\n",
    "        return hit_index, self.hits[hit_index].end_index\n",
    "        \n",
    "    def find_first_downstream_stop(self, starting_from):\n",
    "        # Index suffices to imply frame\n",
    "        i = starting_from\n",
    "        while i < len(self.sequence) - 3:\n",
    "            if self.sequence[i:i+3] == self.stop_codon:\n",
    "                return i\n",
    "            i += 3\n",
    "            \n",
    "    def find_c_terminal_stop_based_on_hits(self, also_upstream=True):\n",
    "        if not self.has_hits():\n",
    "            return None\n",
    "        hit_i, sequence_i = self.closest_to_c_terminus()\n",
    "        # Preferred:\n",
    "        downstream = self.find_first_downstream_stop(sequence_i)\n",
    "        if downstream is not None:\n",
    "            return downstream\n",
    "        elif also_upstream:\n",
    "            i = sequence_i-3\n",
    "            while i > 0:\n",
    "                if self.sequence[i:i+3] == self.stop_codon:\n",
    "                    return i\n",
    "                i -= 3\n",
    "        \n",
    "        return None\n",
    "                \n",
    "    def utr_length(self, require_top_hits=False):\n",
    "        \"\"\"\n",
    "        uses find_c_terminal_stop_based_on_hits\n",
    "        \"\"\"\n",
    "        stop = self.find_c_terminal_stop_based_on_hits()\n",
    "        if stop is None:\n",
    "            return \"no stop\"\n",
    "        if require_top_hits and not self.are_top_hits_close_to_stop(stop):\n",
    "            return \"not enough hits\"\n",
    "        \n",
    "        i = len(self.sequence) - 7\n",
    "        while i > stop:\n",
    "            if \"AAAAAAA\" not in self.sequence[i:i+7]:\n",
    "                return i - stop - 2 # -2 because stop is U's index in UGA\n",
    "            i -= 1\n",
    "    \n",
    "    def are_top_hits_close_to_stop(self, stop_index, tolerance=6, top_n=10, how_many=None):\n",
    "        \"\"\"\n",
    "        stop_index: index of the stop-codon's first base\n",
    "        tolerance: how many amino-acids (!) off may the top matches be?\n",
    "        top_n: Which top matches have to be close? Default: top ten\n",
    "        how_many: how many of the top_n have to be close? \n",
    "        -> top_n=10, how_many=3 can mean that the 8th, 9th and 10th best matches are close\n",
    "         if how_many=None (default), either all top_n, or all the hits (whichever are fewer) have to be close\n",
    "        \"\"\"\n",
    "        tolerance_in_nucleotides = 3 * tolerance \n",
    "        if not self.has_hits() or stop_index is None:\n",
    "            return False\n",
    "        # Unnecessary due to ordering of the hits in Blast-output, but still done for robustness\n",
    "        score_sorted_hits = sorted([h for h in self.hits if h.frame >= 0], \n",
    "                                   key=lambda h: h.score, reverse=True)\n",
    "        \n",
    "        close = 0 \n",
    "        for hit in score_sorted_hits[:np.min((top_n, len(score_sorted_hits)))]:\n",
    "            if np.absolute(hit.end_index - stop_index) <= tolerance:\n",
    "                close += 1\n",
    "        if how_many is None:\n",
    "            return close == np.min((top_n, len(score_sorted_hits)))\n",
    "        return close >= how_many\n",
    "                                             \n",
    "    def list_codon_occurrences(self, codon, origin, relative=True):\n",
    "        postprocess_index = lambda j: j\n",
    "        if relative:\n",
    "            postprocess_index = lambda j: j - origin\n",
    "        occurrences = []\n",
    "        \n",
    "        i = origin - 3\n",
    "        while i > 0:\n",
    "            if self.sequence[i:i+3] == codon:\n",
    "                occurrences.append(postprocess_index(i))\n",
    "            i -= 3\n",
    "            \n",
    "        i = origin\n",
    "        while i < len(self.sequence) - 3:\n",
    "            if self.sequence[i:i+3] == codon:\n",
    "                occurrences.append(postprocess_index(i))\n",
    "            i += 3\n",
    "        return occurrences\n",
    "    \n",
    "    def list_inframe_stops(self, main_stop=None, relative=True, include_UAR=False, include_reference=None):\n",
    "        \"\"\"\n",
    "        Produces a list of indices (always on first base of codon) where UGA=TGA is found in-frame \n",
    "        starting from the main_stop codon.\n",
    "        @param relative: (not yet implemented) if true, should return actual sequence-index, never < 0\n",
    "        @param include_UAR: (not yet implemented) whether to also count UAA/UAG as stops (not in Loxodes)\n",
    "        \"\"\"\n",
    "        if not self.has_hits():\n",
    "            return []\n",
    "        \n",
    "        if main_stop is None:\n",
    "            main_stop = self.find_c_terminal_stop_based_on_hits()\n",
    "            if main_stop is None: # Peculiar case\n",
    "                print(\"%s: No stop could be found based on the %s hits\" % (self.head, len(self.hits)))\n",
    "                return []\n",
    "        \n",
    "        stops = self.list_codon_occurrences(\"TGA\", main_stop, relative=relative)\n",
    "        \n",
    "        if include_UAR:\n",
    "            uaas = self.list_codon_occurrences(\"TAA\", main_stop, relative=relative)\n",
    "            uags = self.list_codon_occurrences(\"TAG\", main_stop, relative=relative)\n",
    "            \n",
    "            return stops, uaas, uags\n",
    "        \n",
    "        return stops\n",
    "    \n",
    "    def codon_counts(self):\n",
    "        # +1 means the first codon is 0:3, +2 means 1:4, +3 means 2:5\n",
    "        # Based on https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi?chapter=cgencodes\n",
    "        # Use the sequence TCAG as default: Yield 4^3=64-entry count-vector\n",
    "        # Go by hits\n",
    "        counts = np.zeros(64)\n",
    "        for hit in self.hits:\n",
    "            if hit.frame < 0:\n",
    "                continue\n",
    "            else:\n",
    "                i = hit.start_index - 1 # First base has ordinal 1. = index 0\n",
    "                while i < hit.end_index - 3:\n",
    "                    counts[codon2index(self.sequence[i:i+3])] += 1\n",
    "                    i += 3\n",
    "        return counts\n",
    "    \n",
    "    def base_frequencies(self):\n",
    "        \"\"\"\n",
    "        computes the base frequencies in the matching region (of the best match) and in the 3'UTR and returns both:\n",
    "        matching region = from start of top match to putative stop (excluding the stop)\n",
    "        3' UTR = from the stop to the 5' end of the poly-A (excluding polyA)\n",
    "        \"\"\"\n",
    "        frequ_match = np.zeros(4)\n",
    "        frequ_utr = np.zeros(4)\n",
    "        # Unnecessary due to ordering of the hits in Blast-output\n",
    "        score_sorted_hits = sorted([h for h in self.hits if h.frame >= 0], \n",
    "                                   key=lambda h: h.score, reverse=True)\n",
    "        match_start = score_sorted_hits[0].start_index - 1 # blast gives ordinals, not indices\n",
    "        stop = self.find_c_terminal_stop_based_on_hits() # this is an index\n",
    "        for i in range(match_start, stop):\n",
    "            frequ_match[base_order.index(self.sequence[i])] += 1\n",
    "        \n",
    "        i = len(self.sequence) - 7\n",
    "        # Move backwards through the Poly-A-tail\n",
    "        while i >= stop:\n",
    "            if \"AAAAAAA\" not in self.sequence[i:i+7]:\n",
    "                break\n",
    "            i -= 1\n",
    "        \n",
    "        # Tail has ended, now collect base frequencies\n",
    "        while i >= stop:\n",
    "            frequ_utr[base_order.index(self.sequence[i])] += 1\n",
    "            i-=1\n",
    "        total = frequ_match + frequ_utr\n",
    "        return frequ_match/np.sum(frequ_match), frequ_utr/np.sum(frequ_utr), total/np.sum(total)\n",
    "        \n",
    "    def base_counts(self, upstream=60, downstream=60):\n",
    "        length = len(self.sequence)\n",
    "        counts = np.zeros((4, upstream + 3 + downstream))\n",
    "        stop = self.find_c_terminal_stop_based_on_hits() # this is an index\n",
    "        for i in range(downstream + 3 + upstream):\n",
    "            sequ_i = min(max(0, stop + i - upstream), length - 1)\n",
    "            counts[base_order.index(self.sequence[sequ_i]), i] = 1\n",
    "        return counts\n",
    "        \n",
    "class Hit:\n",
    "    def __init__(self, name, frame=0, score=0, evalue=0):\n",
    "        self.start_index = None\n",
    "        self.end_index = -1 # last match to query (this is already w.r.t. nucleotides)\n",
    "        self.frame = frame\n",
    "        self.name = name\n",
    "        self.score = score\n",
    "        self.evalue = evalue\n",
    "        self.startline = -1\n",
    "        self.endline = -1\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"%s (ll.%s-%s): Score=%s, E=%s, Frame=%s: %s--%s\" % (self.name, self.startline, self.endline, \n",
    "                                                                    self.score, self.evalue, \n",
    "                                                                    self.frame, self.start_index, self.end_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Read blast-output\n",
    "BlastX of polyA-tailed transcripts (`polyA-terminated.LmagMAC.fasta`) against ciliates.org-derived protein database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = []\n",
    "current_hit = None\n",
    "current_hitname = \"\"\n",
    "with open('blastx_q.polyA_wrt_ciliates_org.out') as blast_result:\n",
    "    for row, line in enumerate(blast_result):\n",
    "        if row % 1e6 == 0:\n",
    "            print(\"@\", row)\n",
    "            \n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "            \n",
    "        if line.startswith(\"Query\"):\n",
    "            if line.startswith(\"Query= \"):\n",
    "                if current_hit is not None and len(transcripts) != 0:\n",
    "                    current_hit.endline = row + 3\n",
    "                    transcripts[-1].hits.append(current_hit)\n",
    "                    current_hit = None\n",
    "                transcripts.append(Transcript(line[7:-1].split(\" \")[0]))\n",
    "            else:\n",
    "                current_hit.endline = row + 3\n",
    "                current_hit.end_index = int(line.split(\" \")[-1])\n",
    "                if current_hit.start_index is None:\n",
    "                    current_hit.start_index = int(line.split(\"  \")[1])\n",
    "        \n",
    "        if line.startswith(\">\"):\n",
    "            current_hitname = line[1:].replace(\"\\t\", \" \")[:-1]\n",
    "            \n",
    "        if line.startswith(\" Score = \"):\n",
    "            if current_hit is not None:\n",
    "                transcripts[-1].hits.append(current_hit)\n",
    "                \n",
    "            current_hit = Hit(current_hitname)\n",
    "            current_hit.startline = row\n",
    "            content = [e.strip() for e in line.split(\",\")]\n",
    "            current_hit.score = float(content[0].split(\" \")[2])\n",
    "            current_hit.evalue = float(content[1].split(\" \")[2])\n",
    "        \n",
    "        if line.startswith(\" Frame = \"):\n",
    "            current_hit.frame = int(line[8:])               \n",
    "        \n",
    "            \n",
    "print(\"Found\", len(transcripts), \"transcripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Read nucleotide sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_dict = {t.head:t for t in transcripts}\n",
    "current = None\n",
    "with open('polyA-terminated.LmagMAC.fasta') as trinity:\n",
    "    for row, line in enumerate(trinity):\n",
    "        if line.startswith(\">\"):\n",
    "            current = transcript_dict[line[1:-1].split(\" \")[0]]\n",
    "        else:\n",
    "            current.sequence = line[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Characterise sense- vs stop-UGA in _Loxodes magnus_\n",
    "### Collect the occurrences of UGA in the transcripts for which the top hits are close to the putative Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices[STOP][other]\n",
    "stop_codons= [\"TGA\", \"TAA\", \"TAG\"]\n",
    "indices = {\"TGA\": {\"TGA\": [], \"TAA\": [], \"TAG\": []}, \n",
    "           \"TAA\": {\"TGA\": [], \"TAA\": [], \"TAG\": []}, \n",
    "           \"TAG\": {\"TGA\": [], \"TAA\": [], \"TAG\": []}}\n",
    "useful_transcripts = {c:[] for c in stop_codons}\n",
    "required_top = {\"TGA\": 4, \"TAA\": 3, \"TAG\": 3}\n",
    "\n",
    "scores = []\n",
    "how_many = {c:0 for c in stop_codons}\n",
    "for i in range(len(transcripts)):\n",
    "    for stop in stop_codons:\n",
    "        transcripts[i].stop_codon = stop\n",
    "        stop_index = transcripts[i].find_c_terminal_stop_based_on_hits(also_upstream=True)\n",
    "        if transcripts[i].are_top_hits_close_to_stop(stop_index, top_n = 10, how_many=required_top[stop]):\n",
    "            how_many[stop] += 1\n",
    "            scores += [h.score for h in transcripts[i].hits]\n",
    "            useful_transcripts[stop].append(transcripts[i])\n",
    "            uga, uaa, uag = transcripts[i].list_inframe_stops(main_stop=stop_index, include_UAR=True)\n",
    "            indices[stop][\"TGA\"] += uga\n",
    "            indices[stop][\"TAA\"] += uaa\n",
    "            indices[stop][\"TAG\"] += uag\n",
    "    \n",
    "    transcripts[i].stop_codon = \"TGA\" # restore default\n",
    "\n",
    "print(\"%s of the transcripts fulfilled the criterion\" % how_many)\n",
    "print(\"Their scores range from %s to %s, mean: %s/median: %s\" % (np.min(scores), np.max(scores), \n",
    "                                                                 np.mean(scores), np.median(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot occurrences of UGA/UAA/UAG relative to putative stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream = 70; downstream = 20\n",
    "filter_start, filter_end = (-3 * upstream, 3 * downstream)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 8)) # , sharey=True)\n",
    "plt.rc('font', size=8) \n",
    "plt.tight_layout(pad=0, h_pad=4, w_pad=4)\n",
    "\n",
    "# /3 to get from nucleotide-index to amino-acids/codons\n",
    "for stop_i in range(len(stop_codons)):\n",
    "    for ref_i in range(len(stop_codons)):\n",
    "        filtered = [i/3 for i in indices[stop_codons[stop_i]][stop_codons[ref_i]] if filter_start <= i <= filter_end]\n",
    "        plot_data = np.zeros(upstream + 1 + downstream) # #codons\n",
    "        for i in filtered:\n",
    "            plot_data[int(i) + upstream] += 1\n",
    "        \n",
    "        # axes[stop_i, ref_i].hist(filtered, bins=60, log=True)\n",
    "        # axes[stop_i, ref_i].axvline(0, color=\"black\", linewidth=1, alpha=1)\n",
    "        axes[stop_i, ref_i].bar(range(-upstream, downstream+1), plot_data, log=True, color=\"tab:blue\")\n",
    "        axes[stop_i, ref_i].set_title(\"absolute prevalence of %s w.r.t Stop-%s\" % (stop_codons[ref_i], stop_codons[stop_i]))\n",
    "        axes[stop_i, ref_i].set_xlabel(\"#codons downstream of Stop-%s\" % stop_codons[stop_i])\n",
    "        axes[stop_i, ref_i].set_ylabel(\"#%s in the transcripts as that codon\" % stop_codons[ref_i])\n",
    "\n",
    "fig.savefig('out/stop_codons_before_stop_codons_all_UAA.UGA.UAG.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting in LaTeX: Write part of this into a csv-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream = 70; downstream = 20\n",
    "filter_start, filter_end = (-3 * upstream, 3 * downstream)\n",
    "\n",
    "# /3 to get from nucleotide-index to amino-acids/codons\n",
    "filtered = [i/3 for i in indices[\"TGA\"][\"TGA\"] if filter_start <= i <= filter_end]\n",
    "uga_data = np.zeros(upstream + 1 + downstream) # #codons\n",
    "for i in filtered:\n",
    "    uga_data[int(i) + upstream] += 1\n",
    "    \n",
    "filtered = [i/3 for i in indices[\"TGA\"][\"TAA\"] if filter_start <= i <= filter_end]\n",
    "uaa_data = np.zeros(upstream + 1 + downstream) # #codons\n",
    "for i in filtered:\n",
    "    uaa_data[int(i) + upstream] += 1\n",
    "\n",
    "with open(\"out/depletion_before_uga.csv\", \"w\") as out:\n",
    "    out.write(\"codon,uga,uaa\\n\") # could actually just write all the codons into this file as columns\n",
    "    for i in range(-upstream, downstream+1):\n",
    "        out.write(\"%s,%s,%s\\n\" % (i, uga_data[i+upstream], uaa_data[i+upstream]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare codon frequencies around UGA-stop\n",
    "Is there a general depletion of some codons (like for UAA), or is this a special feature of UAA?\n",
    "\n",
    "From now on, no longer need the other 'stops'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_transcripts = useful_transcripts[\"TGA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream = 70; downstream = 20\n",
    "filter_start, filter_end = (-3 * upstream, 3 * downstream)\n",
    "\n",
    "# This codon offset serves to define where in the codon-list the plotting shall start \n",
    "# (as only 16 of the 64 codons will be plotted at a time)\n",
    "codon_offset = 0 # 16, 32, 48\n",
    "file_format = \"png\"\n",
    "nrows = 4; ncols = 4\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(10, 8), sharey=True)\n",
    "plt.rc('font', size=8) \n",
    "plt.tight_layout(pad=0, h_pad=4, w_pad=4)\n",
    "\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        indices = []\n",
    "        for i in range(len(useful_transcripts)):\n",
    "            stop_index = useful_transcripts[i].find_c_terminal_stop_based_on_hits(also_upstream=True)\n",
    "            indices += useful_transcripts[i].list_codon_occurrences(codon_list[codon_offset + col + row*ncols], \n",
    "                                                                    stop_index, relative=True)\n",
    "        \n",
    "        filtered = [i/3 for i in indices if filter_start <= i <= filter_end]\n",
    "        plot_data = np.zeros(upstream + 1 + downstream) # #codons\n",
    "        for i in filtered:\n",
    "            plot_data[int(i) + upstream] += 1\n",
    "        \n",
    "        axes[row, col].bar(range(-upstream, downstream+1), plot_data, log=True, color=\"tab:blue\")\n",
    "        axes[row, col].set_title(\"%s\" % codon_list[codon_offset + col + row*ncols])\n",
    "        axes[row, col].set_xlabel(\"#nt from stop-UGA\")\n",
    "        axes[row, col].set_ylabel(\"#%s\" % codon_list[codon_offset + col + row*ncols])\n",
    "\n",
    "fig.savefig('out/codon_usage_%s2%s.%s' % (codon_list[codon_offset], codon_list[codon_offset + nrows * ncols - 1], file_format), \n",
    "            bbox_inches='tight')\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess 3'-UTR-length\n",
    "3'-UTR starts at the found STOP, and ends at=before first consecutive seven A\n",
    "TGA|*UTR*|AAAAAAA\n",
    "\n",
    "Note! This is for a smaller subset of more reliable transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "total_n = 0\n",
    "n_with_any_hits = 0\n",
    "n_no_stop = 0\n",
    "n_not_enough = 0\n",
    "small_n = 0\n",
    "for transcript in transcripts:\n",
    "    total_n += 1\n",
    "    if transcript.has_hits():\n",
    "        n_with_any_hits += 1\n",
    "        length = transcript.utr_length(True)\n",
    "        # if length is not None:\n",
    "        if length not in [\"no stop\", \"not enough hits\"]:\n",
    "            lengths.append(length)    \n",
    "            small_n += 1\n",
    "        elif length == \"no stop\":\n",
    "            n_no_stop += 1\n",
    "        elif length == \"not enough hits\":\n",
    "            n_not_enough += 1\n",
    "            \n",
    "print(\"of all \\t%s transcripts\\n\\t%s had any hits\\n\\t%s thereof were used, while %s had no stop and %s had not enough hits\"\\\n",
    "      % (total_n, n_with_any_hits, small_n, n_no_stop, n_not_enough))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%s of the %s transcripts have a 3'UTR of length 0\" % (len([0 for l in lengths if l == 0]), len(lengths)))\n",
    "print(\"3'UTR-length:\\tmedian=%s\\tmean=%s\\trange: [%s, %s]\" % (np.median(lengths), np.mean(lengths), \n",
    "                                                              np.min(lengths), np.max(lengths)))\n",
    "plt.hist(np.log10(lengths), bins=20, edgecolor=\"k\", color=\"w\", linewidth=0.5, align='left')\n",
    "plt.axvline(np.log10(np.median(lengths)), color=\"r\")\n",
    "plt.axvline(np.log10(np.mean(lengths)), linestyle=\"dashed\", linewidth=0.5)\n",
    "plt.xticks([0, 1, 2, 3], [\"1\", \"10\", \"100\", \"1000\"])\n",
    "plt.xlabel(\"UTR-length\")\n",
    "plt.ylabel(\"#transcripts with this UTR-length\")\n",
    "plt.show()\n",
    "\n",
    "# for latex:\n",
    "hist, bin_edges = np.histogram(np.log10(lengths), bins=20)\n",
    "bar_width = [bin_edges[i+1] - bin_edges[i] for i in range(len(hist))][0]\n",
    "print(\"log(median)=\", np.log10(np.median(lengths)), \"log(mean)=\", np.log10(np.mean(lengths)))\n",
    "print(\"\\nxlower,count\")\n",
    "print(\"\\n\".join([\"%s,%s\" % (l,c) for (c, l) in zip(hist, bin_edges[:-1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess codon and nucleotide biases:\n",
    "\n",
    "Average base frequencies (incl GC-content) for the top-matching region (~coding region) vs 3'-UTR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_frequencies = np.zeros(4)\n",
    "utr_frequencies = np.zeros(4)\n",
    "total_frequencies = np.zeros(4)\n",
    "\n",
    "upstream = 72; downstream = 30\n",
    "counts = np.zeros((4, upstream + 3 + downstream))\n",
    "n = 0\n",
    "for ut in useful_transcripts:\n",
    "    n += 1\n",
    "    m_f, u_f, t_f = ut.base_frequencies()\n",
    "    matching_frequencies += m_f\n",
    "    utr_frequencies += u_f\n",
    "    total_frequencies += t_f\n",
    "    \n",
    "    counts += ut.base_counts(upstream, downstream)\n",
    "\n",
    "counts = counts / n\n",
    "    \n",
    "matching_frequencies = matching_frequencies/len(useful_transcripts)\n",
    "utr_frequencies = utr_frequencies/len(useful_transcripts)\n",
    "total_frequencies = total_frequencies/len(useful_transcripts)\n",
    "\n",
    "print(\"\\t\\tT\\tC\\tA\\tG\\t|\\tGC\")\n",
    "print(\"Matching:\\t%s\\t|\\t%s\" % (\"\\t\".join([str(np.round(f, 3)) for f in matching_frequencies]), \n",
    "                                matching_frequencies[1] + matching_frequencies[3]))\n",
    "print(\"3'-UTR:\\t\\t%s\\t|\\t%s\" % (\"\\t\".join([str(np.round(f, 3)) for f in utr_frequencies]), \n",
    "                             utr_frequencies[1] + utr_frequencies[3]))\n",
    "print(\"total:\\t\\t%s\\t|\\t%s\" % (\"\\t\".join([str(np.round(f, 3)) for f in total_frequencies]), \n",
    "                             total_frequencies[1] + total_frequencies[3]))\n",
    "\n",
    "plt.plot(range(-upstream, 3+downstream), counts[0,], label=\"U\")\n",
    "plt.plot(range(-upstream, 3+downstream), counts[1,], label=\"C\")\n",
    "plt.plot(range(-upstream, 3+downstream), counts[2,], label=\"A\")\n",
    "plt.plot(range(-upstream, 3+downstream), counts[3,], label=\"G\")\n",
    "plt.xlabel(\"#nucleotides downstream of stop-UGA's U\")\n",
    "plt.ylabel(\"base-frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "with open(\"out/base_frequencies.csv\", \"w\") as out:\n",
    "    out.write(\"nt,u,c,a,g\\n\")\n",
    "    for i in range(-upstream, 3+downstream):\n",
    "        out.write(\"%s,%s,%s,%s,%s\\n\" % (i, counts[0,i+upstream], counts[1,i+upstream], \n",
    "                                      counts[2,i+upstream], counts[3,i+upstream]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect codon-usage in the matching regions\n",
    "\n",
    "Note: setting `recompute = True` will then trigger a rather slow computation, which is why the option to abbreviate this exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = False\n",
    "# This was computed in a previous run (to save time):\n",
    "counts = np.array([0.035354874328046015, 0.014842373647985943, 0.032875613243826006, 0.014088955968809047, \n",
    "                   0.01900080444301719, 0.00356805161649493, 0.016410789395218176, 0.003566107265019291, \n",
    "                   0.03079942547932245, 0.010243065785261898, 0.03256178565684137, 0.01396590629685077, \n",
    "                   0.011364882516173022, 0.009150627279266018, 0.008338184644578662, 0.010085452951120004, \n",
    "                   0.020381914331429562, 0.0037948926219861117, 0.014436013448394005, 0.004193003216031411, \n",
    "                   0.015471778738283292, 0.001843448892869604, 0.010669637981383926, 0.0008325064901526376, \n",
    "                   0.016098859865626425, 0.004345440371721485, 0.012871421592397193, 0.00419746596560883, \n",
    "                   0.0026233930814641418, 0.0008647086541158347, 0.002690945407017761, 0.00021116582907091368, \n",
    "                   0.0390077552217781, 0.011168493758316963, 0.031892650984725136, 0.019177258968839674, \n",
    "                   0.023849905917461504, 0.003764495927250293, 0.015866139511625573, 0.00358642110853144, \n",
    "                   0.042859895106496945, 0.017490700722421013, 0.055141659708048775, 0.024078061674902878, \n",
    "                   0.017581761183196758, 0.00807422504353588, 0.024174140414249083, 0.004461342237302653, \n",
    "                   0.021964607173782912, 0.004501127372020842, 0.019434348528001865, 0.005903606609032139, \n",
    "                   0.024355159536631046, 0.003895461887359386, 0.016787743593445217, 0.002529610528622502, \n",
    "                   0.04129483105085605, 0.011945771407744912, 0.046644269712881506, 0.014030486542291627, \n",
    "                   0.015584338171089672, 0.005736170170529994, 0.03738262922317307, 0.004091433998470666])\n",
    "\n",
    "\n",
    "if recompute:\n",
    "    counts = np.zeros(64)\n",
    "    for i in range(len(transcripts)):\n",
    "        if i % 1e2 == 0:\n",
    "            print(\"@\", i, end=\" - \")\n",
    "        if i % 1e3 == 900:\n",
    "            print(\"|\")\n",
    "        counts += transcripts[i].codon_counts()\n",
    "\n",
    "\n",
    "    counts = counts/np.sum(counts)\n",
    "    \n",
    "print(\"\\n%s\" % (counts * 64)) # > 1 means overrepresented compared to naive Null-model (uniform)\n",
    "print(counts[codon2index(\"TGA\")])\n",
    "\n",
    "# UGA is underrepresented w.r.t. uniform 0-model; but not remarkably so\n",
    "print(\"\\nUGA-usage:\", counts[codon2index(\"TGA\")] * 64) \n",
    "print(\"UGG-usage:\", counts[codon2index(\"TGG\")] * 64) \n",
    "# this is the other Typtophane-codon: it is also slightly underrepresented\n",
    "\n",
    "# Marginalise to get base-usage for codon-pos 0, 1, 2\n",
    "# then remultiply (independency-assumption) and compare\n",
    "independent_codon_approximation = fit_codon_usage(counts)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "w = 0.3\n",
    "plt.bar(np.arange(64) - w/2, 64*counts, width=w)\n",
    "plt.bar(np.arange(64) + w/2, 64*independent_codon_approximation, width=w)\n",
    "plt.xticks(range(64), codon_list, rotation=90)\n",
    "plt.axhline(1, color=\"k\", linewidth=0.5)\n",
    "\n",
    "plt.show()\n",
    "# W-codons are TGA and TGG\n",
    "# AAA-usage is suspiciously high (-> polyA? -- i rely on the hits to stop before polyA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Blue: empirical codon usage relative to uniform distribution\n",
    "- Orange: independent-base-wise approximation relative to uniform distribution\n",
    "\n",
    "The horizontal line marks exact accord with a uniform distribution. Any bar above it means the codon is overrepresented, any below means underrepresented. Contrast the good agreement of the two models e.g. for ATT as opposed to the strong disagreement for GGA and CTT (the latter over- vs underrepresented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recompute:\n",
    "    print(\", \".join([str(c) for c in counts])) # copy this into above cell if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position Count/Probability/Weight Matrices\n",
    "Further of interest: base and codon use left and right of UGA (stop vs sense)\n",
    "\n",
    "Include pseudocounts outside the stop-UGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream = 21; downstream = 12 # 3\n",
    "pattern_length = upstream + 3 + downstream\n",
    "\n",
    "count_matrix_stop = np.ones((4, pattern_length)) # codon to the left, Stop, codon to the right\n",
    "count_matrix_sense = np.ones((4, pattern_length))\n",
    "count_matrix_utr = np.ones((4, pattern_length))\n",
    "\n",
    "\"\"\"\n",
    "Without any pseudocounts:\n",
    "count_matrix_stop = np.zeros((4, pattern_length)) \n",
    "count_matrix_sense = np.zeros((4, pattern_length))\n",
    "count_matrix_utr = np.zeros((4, pattern_length))\n",
    "\"\"\"\n",
    "\n",
    "count_matrix_stop[:,upstream:upstream+3] = 0 # stop-UGA: no pseudocounts\n",
    "count_matrix_sense[:,upstream:upstream+3] = 0 # stop-UGA: no pseudocounts\n",
    "count_matrix_utr[:,upstream:upstream+3] = 0 # stop-UGA: no pseudocounts\n",
    "\n",
    "\n",
    "for transcript in useful_transcripts:\n",
    "    main_stop = transcript.find_c_terminal_stop_based_on_hits()\n",
    "    shifted = False\n",
    "    if transcript.sequence[main_stop-6:main_stop-3] == \"TGA\":\n",
    "        main_stop -= 6\n",
    "        shifted = True\n",
    "    elif transcript.sequence[main_stop-9:main_stop-6] == \"TGA\":\n",
    "        main_stop -= 9\n",
    "        shifted = True\n",
    "    elif transcript.sequence[main_stop-12:main_stop-9] == \"TGA\":\n",
    "        main_stop -= 12\n",
    "        shifted = True\n",
    "    while transcript.sequence[main_stop-3:main_stop] == \"TGA\":\n",
    "        main_stop -= 3\n",
    "        shifted = True\n",
    "    \n",
    "    if shifted:\n",
    "        print(transcript.head, \"got shifted!\")\n",
    "    \n",
    "    \n",
    "    UGA_occurrences = transcript.list_inframe_stops(main_stop=main_stop, relative=False)\n",
    "    for occurrence in UGA_occurrences:\n",
    "        relevant = None\n",
    "        if occurrence == main_stop:\n",
    "            relevant = count_matrix_stop\n",
    "        elif occurrence < main_stop:\n",
    "            relevant = count_matrix_sense\n",
    "        else:\n",
    "            relevant = count_matrix_utr        \n",
    "        \n",
    "        for j in range(pattern_length):\n",
    "            if occurrence + j - upstream < len(transcript.sequence):\n",
    "                relevant[base_order.index(transcript.sequence[occurrence + j - upstream]), j] += 1\n",
    "    \n",
    "print(\"Sense:\", np.sum(count_matrix_sense, axis=0)[0])\n",
    "print(\"STOPs:\", np.sum(count_matrix_stop, axis=0)[0])\n",
    "print(\"3'UTR:\", np.sum(count_matrix_utr, axis=0)[0])\n",
    "    \n",
    "probability_matrix_stop = count_matrix_stop / np.sum(count_matrix_stop, axis=0) # same #sequences for all columns\n",
    "probability_matrix_sense = count_matrix_sense / np.sum(count_matrix_sense, axis=0)\n",
    "probability_matrix_utr = count_matrix_utr / np.sum(count_matrix_utr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PPM around sense stop\")\n",
    "print(np.round(probability_matrix_sense, 3)) \n",
    "print(np.sum(probability_matrix_sense, axis=0))\n",
    "print(\"\\nPPM around full stop\")\n",
    "print(np.round(probability_matrix_stop, 3))\n",
    "print(np.sum(probability_matrix_stop, axis=0))\n",
    "print(\"\\nPPM around utr stop\")\n",
    "print(np.round(probability_matrix_utr, 3)) \n",
    "print(np.sum(probability_matrix_utr, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation into a Position Weight Matrix (PWM):\n",
    "Use a position-dependent background model to account for different base composition of UTR and ~coding region. Use the empirical base frequencies computed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "file_format = \"pdf\"\n",
    "# matching_frequencies and utr_frequencies\n",
    "PWM_sense = np.log2(probability_matrix_sense / np.tile(matching_frequencies, pattern_length).reshape(pattern_length, 4).T)\n",
    "PWM_utr = np.log2(probability_matrix_utr / np.tile(utr_frequencies, pattern_length).reshape(pattern_length, 4).T)\n",
    "PWM_stop = np.log2(probability_matrix_stop / np.append(np.tile(matching_frequencies, upstream), \n",
    "                                                       np.tile(utr_frequencies, 3 + downstream)).reshape(pattern_length, 4).T)\n",
    "\n",
    "pwms = [PWM_sense, PWM_stop, PWM_utr]\n",
    "xticks = [i for i in range(upstream + 3 + downstream) if (i - upstream) % 3 == 1]\n",
    "ylabels = [\"sense\", \"stop\", \"utr\"]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3)\n",
    "\n",
    "for a in range(len(axes)):\n",
    "    im = axes[a].imshow(pwms[a], vmin=-1.75, vmax=3.562, cmap=\"coolwarm\", \n",
    "                        norm=colors.TwoSlopeNorm(vmin=-1.75, vcenter=0., vmax=3.562))\n",
    "    axes[a].set_xticks(xticks)\n",
    "    axes[a].set_xticklabels(np.array((np.array(xticks) - upstream - 1)/3, dtype=int))\n",
    "    \n",
    "    axes[a].set_yticks([1.5])\n",
    "    axes[a].set_yticklabels([ylabels[a]])\n",
    "\n",
    "plt.tight_layout(h_pad = -15)\n",
    "fig.colorbar(im, ax=axes, shrink=0.5)\n",
    "    \n",
    "fig.savefig('out/PWMs.%s' % file_format, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(upstream+downstream+3)\n",
    "\n",
    "print(\"PWM around sense UGA\")\n",
    "print(np.round(PWM_sense, 3))\n",
    "print(\"\\nPWM around stop UGA\")\n",
    "print(np.round(PWM_stop, 3))\n",
    "print(\"\\nPWM around 3'UTR UGA\")\n",
    "print(np.round(PWM_utr, 3))\n",
    "\n",
    "print(\"Range of sense-PWM: [%s, %s]\" % (np.min(PWM_sense[:,:upstream]), np.max(PWM_sense)))\n",
    "print(\"Range of stop-PWM: [%s, %s]\" % (np.min(PWM_stop[:,:upstream]), np.max(PWM_stop)))\n",
    "print(\"Range of UTR-PWM: [%s, %s]\" % (np.min(PWM_utr[:,upstream+3:]), np.max(PWM_utr)))\n",
    "\n",
    "print(\"without respect for the -inf-entries at the UGA of course\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing PPMs (probability matrices) according to Aerts, Loo, Thijs, DeMoor, Moreau (2003): Use symmetrized KL:\n",
    "$c_{1,2} := \\frac{1}{w}\\sum_{j=1}^{w}\\sum_{b\\in\\{T,C,A,G\\}}\\Theta_{1}(j,b)\\log_2\\frac{\\Theta_1(j,b)}{\\Theta_2(j,b)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(ppm1, ppm2):\n",
    "    # indices j are here already known to be 0,1,2,6,7,8; w=6\n",
    "    indices = [i for i in range(upstream + 3 + downstream) if i < upstream or i >= upstream + 3]\n",
    "    result = 0\n",
    "    for j in indices:\n",
    "        for b in range(4):\n",
    "            result += ppm1[b, j] * np.log(ppm1[b, j] / ppm2[b, j])\n",
    "    return result / len(indices)\n",
    "\n",
    "def symm_KL(M, N):\n",
    "    return 0.5*(KL(M, N) + KL(N, M))\n",
    "\n",
    "print(\"distance sense<->stop\\t\", symm_KL(probability_matrix_sense, probability_matrix_stop))\n",
    "print(\"distance sense<->utr\\t\", symm_KL(probability_matrix_sense, probability_matrix_utr))\n",
    "print(\"distance stop<->utr\\t\", symm_KL(probability_matrix_stop, probability_matrix_utr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aerts et al. set 'high-stringency' threshold at 0.2 (for 'same'): these here can be assumed to be same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Comparison to other ciliates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complement = {\"T\":\"A\", \"C\":\"G\", \"A\":\"T\", \"G\":\"C\", \"N\":\"N\"}\n",
    "\n",
    "def reverse_complement(sequence):\n",
    "    return \"\".join([complement[b] for b in sequence[::-1]])\n",
    "\n",
    "class Gene:\n",
    "    def __init__(self, start, end, strand):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.forward = strand == \"+\"\n",
    "        self.validated = False # use this to check for CDS\n",
    "        \n",
    "    def feasible(self, sequence, upstream, downstream):\n",
    "        if self.forward:                \n",
    "            return self.end-3-3*upstream >= 0 and self.end + 3*downstream < len(sequence)\n",
    "        else:\n",
    "            return self.start-1-3*downstream >= 0 and self.start + 2 + 3*upstream < len(sequence)\n",
    "    \n",
    "    def count_codons(self, sequence, upstream = 60, downstream=20):\n",
    "        \"\"\" upstream and downstream are in codons (not nt) \"\"\"\n",
    "        if self.forward:                \n",
    "            relevant = sequence[self.end-3-3*upstream : self.end + 3*downstream]\n",
    "        else:\n",
    "            relevant = sequence[self.start-1-3*downstream : self.start + 2 + 3*upstream]\n",
    "            relevant = reverse_complement(relevant)\n",
    "        # print(relevant[:upstream*3], relevant[3*upstream:3*upstream+3], relevant[3*upstream+3:])\n",
    "        count = np.zeros((upstream + 1 + downstream, 64))\n",
    "        for i in range(upstream + downstream + 1):\n",
    "            if \"N\" not in relevant[3*i:3*i+3]:\n",
    "                count[i, codon2index(relevant[3*i:3*i+3])] += 1\n",
    "            else:\n",
    "                print(\"! ENCOUNTERED N !\")\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameters: Upstream and downstream windows (in codons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = 60\n",
    "down = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing data-files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parsing of GFF-file:\n",
    "### (uses up and down)\n",
    "def parse_gff(file, work_dict, validator=\"CDS\"):\n",
    "    with open(file) as annotation:\n",
    "        for line in annotation:\n",
    "            if \"gene\" in line:\n",
    "                contents = line.split(\"\\t\")\n",
    "                if contents[6] not in \"+-\":\n",
    "                    # The Euplotes annotation seems not very good\n",
    "                    continue\n",
    "                \n",
    "                if contents[0] not in work_dict:\n",
    "                    work_dict[contents[0]] = [Gene(int(contents[3]), int(contents[4]), contents[6])]\n",
    "                work_dict[contents[0]].append(Gene(int(contents[3]), int(contents[4]), contents[6]))\n",
    "\n",
    "    with open(file) as annotation:\n",
    "        for line in annotation:\n",
    "            if validator in line:\n",
    "                contents = line.split(\"\\t\")\n",
    "                strand = contents[6] == \"+\"\n",
    "                start = int(contents[3])\n",
    "                end = int(contents[4])\n",
    "                if contents[0] in work_dict:\n",
    "                    for g in [g for g in work_dict[contents[0]] if g.forward == strand and (g.start == start or g.end == end)]:\n",
    "                        if (strand and end == g.end and start <= g.end - 3*(1+up)) or (not strand and start == g.start and end >= g.start + 2 + 3*up):\n",
    "                            g.validated = True\n",
    "                            \n",
    "### Parsing of fasta under given annotation\n",
    "def apply_gff(fasta, genes):\n",
    "    g_c = 0\n",
    "    codon_counts = np.zeros((up + 1 + down, 64))\n",
    "    with open(fasta) as assembly:\n",
    "        current_sequence = \"\"\n",
    "        current_header = None\n",
    "        for line in assembly:\n",
    "            if line.startswith(\">\"):\n",
    "                if current_header is not None and current_header in genes:\n",
    "                    print(current_header)\n",
    "                    for g in genes[current_header]:\n",
    "                        if g.validated and g.feasible(current_sequence, up, down):\n",
    "                            g_c += 1\n",
    "                            # print(\"\\t%s%s%s\" % (g.start, \">\" if g.forward else \"<\", g.end))\n",
    "                            print(\"%s gene %s%s%s (len: %s)\" %(g_c,g.start, \"+\" if g.forward else \"-\", g.end, len(current_sequence)))\n",
    "                            codon_counts += g.count_codons(current_sequence, up, down)\n",
    "                            print(\"\\tTAA: %s\\tTAG: %s\\tTGA: %s\" % (codon_counts[up, codon2index(\"TAA\")],\n",
    "                                                                   codon_counts[up, codon2index(\"TAG\")],\n",
    "                                                                   codon_counts[up, codon2index(\"TGA\")]))\n",
    "                        else:\n",
    "                            if g.validated:\n",
    "                                print(\"\\ntoo close to edges\\n\")\n",
    "                            else:\n",
    "                                print(\"\\n-> No sufficient CDS found\\n\")\n",
    "                current_header = line[1:-1]\n",
    "                current_sequence = \"\"\n",
    "            else:\n",
    "                current_sequence += line[:-1]\n",
    "    return codon_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 _Tetrahymena thermophila_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_tetra = {} # contig:[genes] pairs\n",
    "parse_gff(\"ciliates/tetrahymena_annotation.gff3\", genes_tetra, validator=\"CDS\")\n",
    "codon_counts_tetra = apply_gff(\"ciliates/tetrahymena_assembly.fasta\", genes_tetra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 _Stentor coeruleus_\n",
    "Uses the standard genetic code, so do not expect UGA/UAA-depletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_stentor = {} # contig:[genes] pairs\n",
    "parse_gff(\"ciliates/S_coeruleus_Nov2016.gff3\", genes_stentor, validator=\"CDS\")\n",
    "codon_counts_stentor = apply_gff(\"ciliates/S_coeruleus_Nov2016_assembly.fasta\", genes_stentor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising column-wise (per position)\n",
    "normalised_stentor = codon_counts_stentor.T / np.sum(codon_counts_stentor, axis=1)\n",
    "normalised_tetra = codon_counts_tetra.T / np.sum(codon_counts_tetra, axis=1)\n",
    "# [codon, pos]\n",
    "print(normalised_stentor.shape)\n",
    "print(np.sum(normalised_stentor, axis=0)) # summing over all codons at a certain position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = range(-up, 1+down)\n",
    "highlight_stop = [\"tab:orange\" if x == 0 else \"tab:blue\" for x in xs]\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.title(\"UGA\")\n",
    "plt.ylabel(\"Tetrahymena\")\n",
    "plt.bar(xs, normalised_tetra[codon2index(\"TGA\")], color=highlight_stop, width=1) # this should be the only stop\n",
    "plt.ylim(0, 0.05)\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.title(\"UAA\")\n",
    "plt.bar(xs, normalised_tetra[codon2index(\"TAA\")], color=highlight_stop, width=1)\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.title(\"UAG\")\n",
    "plt.bar(xs, normalised_tetra[codon2index(\"TAG\")], color=highlight_stop, width=1)\n",
    "\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.title(\"UGA\")\n",
    "plt.ylabel(\"Stentor\")\n",
    "plt.bar(xs, normalised_stentor[codon2index(\"TGA\")], color=highlight_stop, width=1)\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.title(\"UAA\")\n",
    "plt.bar(xs, normalised_stentor[codon2index(\"TAA\")], color=highlight_stop, width=1)\n",
    "plt.xlabel(\"#codons downstream of stop\")\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.title(\"UAG\")\n",
    "plt.bar(xs, normalised_stentor[codon2index(\"TAG\")], color=highlight_stop, width=1)\n",
    "\n",
    "plt.tight_layout(pad=3, h_pad=2, w_pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Conserved _Tetrahymena_ proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_of_interest = {} # contig:[(hit, qstart, qend, sstart, send)]\n",
    "with open(\"ciliates/blastx_q.transcriptome_wrt_conserved_tetrahymena.out\") as blast:\n",
    "    for line in blast:\n",
    "        qseqid, sseqid, pident, length, mismatch, gapopen, qstart, qend, sstart, send, evalue, bitscore = line.split(\"\\t\")\n",
    "        qstart, qend, sstart, send = [int(i) for i in [qstart, qend, sstart, send]]\n",
    "        if qseqid in regions_of_interest:\n",
    "            regions_of_interest[qseqid] += [(sseqid, qstart, qend, sstart, send)]\n",
    "        else:\n",
    "            regions_of_interest[qseqid] = [(sseqid, qstart, qend, sstart, send)]\n",
    "        # print(qseqid, sseqid, qstart < qend, sstart < send)\n",
    "\n",
    "upstream = 72; downstream = 30\n",
    "periterminal_sequences = []\n",
    "inframe_stops = []\n",
    "inframe_taa = []\n",
    "utr_lengths = []\n",
    "\n",
    "with open(\"Lmag_transcriptome.fasta\") as transcriptome:\n",
    "    current_head = None\n",
    "    current_sequence = \"\"\n",
    "    for line in transcriptome:\n",
    "        if line.startswith(\">\"):\n",
    "            if current_head is not None:\n",
    "                if current_head in regions_of_interest:\n",
    "                    for g in regions_of_interest[current_head]:\n",
    "                        hit, qstart, qend, sstart, send = g\n",
    "                        print(current_head, qstart, qend, hit, sstart, send)\n",
    "                        polyA_start = len(current_sequence) - 1\n",
    "                        for i in range(len(current_sequence) - 1, 0, -1):\n",
    "                            if current_sequence[i] == \"A\":\n",
    "                                polyA_start = i\n",
    "                            else:\n",
    "                                break\n",
    "                        stop = -1\n",
    "                        # here doing -3 because of the below-described case!\n",
    "                        for i in range(qend-3, len(current_sequence), 3):\n",
    "                            if current_sequence[i:i+3] == \"TGA\":\n",
    "                                stop = i\n",
    "                                if i-qend <= 90:\n",
    "                                    periterminal_sequences += [current_sequence[i-upstream:i+downstream+3]]\n",
    "                                    utr_lengths += [polyA_start - i] # UGA is part of the UTR\n",
    "                                    \n",
    "                                    for j in range(i, len(current_sequence), 3):\n",
    "                                        if current_sequence[j:j+3] == \"TGA\":\n",
    "                                            inframe_stops.append(j-i)\n",
    "                                        elif current_sequence[j:j+3] == \"TAA\":\n",
    "                                            inframe_taa.append(j-i)\n",
    "                                    for j in range(i-3, 0, -3):\n",
    "                                        if current_sequence[j:j+3] == \"TGA\":\n",
    "                                            inframe_stops.append(j-i)\n",
    "                                            if j-i >= -10:\n",
    "                                                print(\"! very close stop\", current_head, j-i, \"\\n\")\n",
    "                                        elif current_sequence[j:j+3] == \"TAA\":\n",
    "                                            inframe_taa.append(j-i)\n",
    "                                break\n",
    "            current_head = line[1:-1].split(\" \")[0]\n",
    "            current_sequence = \"\"\n",
    "        else:\n",
    "            current_sequence += line[:-1]\n",
    "            \n",
    "print(\"Found %s transcripts with sufficiently high scoring alignment to one of the conserved proteins\" % \n",
    "      len(periterminal_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are a few cases, where UGA occurs directly before the putative stop:\n",
    "All of these match to 60S_ribosomal_protein_L39_chr_024, and can be reasonably moved by one codon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"3'UTR-length:\\tmedian=%s\\tmean=%s\\trange: [%s, %s]\" % (np.median(utr_lengths), \n",
    "                                                              np.mean(utr_lengths),\n",
    "                                                              np.min(utr_lengths), \n",
    "                                                              np.max(utr_lengths)))\n",
    "\n",
    "plt.hist(np.log10(utr_lengths), bins=20, edgecolor=\"k\", color=\"w\", linewidth=0.5, align='left')\n",
    "plt.axvline(np.log10(np.median(utr_lengths)), color=\"r\")\n",
    "plt.axvline(np.log10(np.mean(utr_lengths)), linestyle=\"dashed\", linewidth=0.5)\n",
    "plt.xticks([0, 1, 2, 2.681241237375587, 3], [\"1\", \"10\", \"100\", \"480\", \"1000\"])\n",
    "plt.xlabel(\"UTR-length\")\n",
    "plt.ylabel(\"#transcripts with this UTR-length\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# for latex:\n",
    "hist, bin_edges = np.histogram(np.log10(utr_lengths), bins=20)\n",
    "bar_width = [bin_edges[i+1] - bin_edges[i] for i in range(len(hist))][0]\n",
    "print(len(hist), bar_width * 2, \"log(median)=\", np.log10(np.median(utr_lengths)), \n",
    "      \"log(mean)=\", np.log10(np.mean(utr_lengths)))\n",
    "print(\"log(20)=\", np.log10(20), \"log(400)=\", np.log10(400))\n",
    "result = \"xlower,count\\n\"\n",
    "result += \"\\n\".join([\"%s,%s\" % (l,c) for (c, l) in zip(hist, bin_edges[:-1])])\n",
    "with open(\"out/tetrah_utr_lengths.csv\", \"w\") as out:\n",
    "    out.write(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros((4, upstream + 3 + downstream))\n",
    "n = 0\n",
    "for seq in periterminal_sequences:\n",
    "    if len(seq) == upstream + 3 + downstream:\n",
    "        n += 1\n",
    "        for i in range(upstream + 3 + downstream):\n",
    "            counts[base_order.index(seq[i]), i] += 1\n",
    "\n",
    "print(n)\n",
    "counts = counts/n\n",
    "    \n",
    "plt.plot(range(-upstream, 3+downstream), counts[0,], label=\"U\")\n",
    "plt.plot(range(-upstream, 3+downstream), counts[1,], label=\"C\")\n",
    "plt.plot(range(-upstream, 3+downstream), counts[2,], label=\"A\")\n",
    "plt.plot(range(-upstream, 3+downstream), counts[3,], label=\"G\")\n",
    "plt.xlabel(\"#nucleotides downstream of stop-UGA's U\")\n",
    "plt.ylabel(\"base-frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# print(\"\\n\".join(periterminal_sequences))\n",
    "print(\"clearly very noisy due to small sample size\")\n",
    "\n",
    "with open(\"out/tetrah_base_frequencies.csv\", \"w\") as out:\n",
    "    out.write(\"nt,u,c,a,g\\n\")\n",
    "    for i in range(-upstream, 3+downstream):\n",
    "        out.write(\"%s,%s,%s,%s,%s\\n\" % (i, counts[0,i+upstream], counts[1,i+upstream], \n",
    "                                        counts[2,i+upstream], counts[3,i+upstream]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_codons = 200\n",
    "downstream_codons = 20\n",
    "stop_counts = np.zeros(upstream_codons + 1 + downstream_codons)\n",
    "taa_counts = np.zeros(upstream_codons + 1 + downstream_codons)\n",
    "# print(inframe_stops)\n",
    "for stop in [s for s in inframe_stops if -3*upstream_codons <= s <= 3*downstream_codons]:\n",
    "    if stop % 3 != 0:\n",
    "        print(\"sth went wrong, not divisble by 3\")\n",
    "    stop_counts[int(stop/3) + upstream_codons] += 1\n",
    "    \n",
    "for taa in [s for s in inframe_taa if -3*upstream_codons <= s <= 3*downstream_codons]:\n",
    "    if taa % 3 != 0:\n",
    "        print(\"sth went wrong, not divisble by 3\")\n",
    "    taa_counts[int(taa/3) + upstream_codons] += 1\n",
    "    \n",
    "print(stop_counts[upstream_codons], taa_counts[upstream_codons])\n",
    "    \n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(range(-upstream_codons, downstream_codons + 1), stop_counts)\n",
    "plt.xlabel(\"#codons upstream if inferred stop\")\n",
    "plt.ylabel(\"#UGA\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(range(-upstream_codons, downstream_codons + 1), taa_counts)\n",
    "plt.xlabel(\"#codons upstream if inferred stop\")\n",
    "plt.ylabel(\"#UAA\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Do not find any UGA upstream in a big window!\\nWhile this is not quite the same sight as for the heuristic, there at least is no eclatant contradiction\")\n",
    "\n",
    "with open(\"out/tetrah_depletion_before_uga.csv\", \"w\") as out:\n",
    "    out.write(\"codon,uga,uaa\\n\")\n",
    "    for i in range(-upstream_codons, downstream_codons+1):\n",
    "        out.write(\"%s,%s,%s\\n\" % (i, stop_counts[i+upstream_codons], taa_counts[i+upstream_codons]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
